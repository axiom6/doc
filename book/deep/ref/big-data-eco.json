[
  {
    "name": "2lemetry",
    "description": "Platform for Internet of things",
    "abstract": "Platform for Internet of things",
    "category": "Internet of Things",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://2lemetry.com/"
      }
    ]
  },
  {
    "name": "Actian Ingres",
    "description": "commercially supported, open-source SQL relational database management system",
    "abstract": "commercially supported, open-source SQL relational database management system",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.actian.com/products/operational-databases/"
      }
    ]
  },
  {
    "name": "Actian PSQL",
    "description": "ACID-compliant DBMS developed by Pervasive Software, optimized for embedding in applications",
    "abstract": "ACID-compliant DBMS developed by Pervasive Software, optimized for embedding in applications",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.actian.com/products/operational-databases/"
      }
    ]
  },
  {
    "name": "Actian SQL for Hadoop",
    "description": "high performance interactive SQL access to all Hadoop data",
    "abstract": "high performance interactive SQL access to all Hadoop data",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.actian.com/products/analytics-platform/"
      }
    ]
  },
  {
    "name": "Actian Vector",
    "description": "column-oriented analytic database",
    "abstract": "column-oriented analytic database",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Actian website",
        "url": "http://www.actian.com/"
      }
    ]
  },
  {
    "name": "Actian Versant",
    "description": "commercial object-oriented database management systems ",
    "abstract": "commercial object-oriented database management systems ",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.actian.com/products/operational-databases/"
      }
    ]
  },
  {
    "name": "ActiveMQ",
    "description": "open source messaging and Integration Patterns server",
    "abstract": "open source messaging and Integration Patterns server",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://activemq.apache.org/"
      }
    ]
  },
  {
    "name": "ActivePivot",
    "description": "Java In-Memory OLAP cube stored in columns, with clearly decoupled pre/post processing",
    "abstract": "Java In-Memory OLAP cube stored in columns, with clearly decoupled pre/post processing",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://quartetfs.com/products/activepivot"
      }
    ]
  },
  {
    "name": "Adatao",
    "description": "business intelligence and data science platform",
    "abstract": "business intelligence and data science platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://adatao.com/pinsights.html"
      }
    ]
  },
  {
    "name": "AddThis Hydra",
    "description": "Hydra is a distributed data processing and storage system originally developed at AddThis. It ingests streams of data (think log files) and builds trees that are aggregates, summaries, or transformations of the data. These trees can be used by humans to explore (tiny queries), as part of a machine learning pipeline (big queries), or to support live consoles on websites (lots of queries).",
    "abstract": "distributed data processing and storage system originally developed at AddThis",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/addthis/hydra"
      }
    ]
  },
  {
    "name": "Adobe Spindle",
    "description": "Next-generation web analytics processing with Scala, Spark, and Parquet",
    "abstract": "Next-generation web analytics processing with Scala, Spark, and Parquet",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/adobe-research/spindle"
      }
    ]
  },
  {
    "name": "Aerospike",
    "description": "NoSQL flash-optimized, in-memory. Open source and \"Server code in 'C' (not Java or Erlang) precisely tuned to avoid context switching and memory copies.",
    "abstract": "NoSQL flash-optimized, in-memory. Open source and \"Server code in 'C' (not Java or Erlang) precisely tuned to avoid context switching and memory copies.",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.aerospike.com/"
      }
    ]
  },
  {
    "name": "Akela",
    "description": "Mozilla's utility library for Hadoop, HBase, Pig, etc.",
    "abstract": "Mozilla's utility library for Hadoop, HBase, Pig, etc.",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/mozilla-metrics/akela"
      }
    ]
  },
  {
    "name": "Akka Toolkit",
    "description": "Akka is an open-source toolkit and runtime simplifying the construction of concurrent applications on the Java platform.",
    "abstract": "runtime for distributed, and fault tolerant event-driven applications on the JVM",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://akka.io/"
      }
    ]
  },
  {
    "name": "Amazon Aurora",
    "description": "a MySQL-compatible, relational database engine that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open source databases",
    "abstract": "a MySQL-compatible, relational database engine that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open source databases",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://aws.amazon.com/rds/aurora/"
      }
    ]
  },
  {
    "name": "Amazon DynamoDB",
    "description": "distributed key/value store, implementation of Dynamo",
    "abstract": "distributed key/value store, implementation of Dynamo paper",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Amazon DynamoDB",
        "url": "http://aws.amazon.com/dynamodb/"
      }
    ]
  },
  {
    "name": "Amazon EC2 Container Service",
    "description": "a highly scalable, high performance container management service that supports Docker containers",
    "abstract": "a highly scalable, high performance container management service that supports Docker containers",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://aws.amazon.com/ecs/"
      }
    ]
  },
  {
    "name": "Amazon Kinesis",
    "description": "Real-time processing of streaming data at massive scale",
    "abstract": "real-time processing of streaming data at massive scale",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Amazon Kinesis",
        "url": "http://aws.amazon.com/kinesis/"
      }
    ]
  },
  {
    "name": "Amazon Lambda",
    "description": "a compute service that runs your code in response to events and automatically manages the compute resources for you",
    "abstract": "a compute service that runs your code in response to events and automatically manages the compute resources for you",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://aws.amazon.com/lambda/"
      }
    ]
  },
  {
    "name": "Amazon RDS",
    "description": "MySQL databases in Amazon's cloud",
    "abstract": "MySQL databases in Amazon's cloud",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Amazon RDS",
        "url": "http://aws.amazon.com/rds/"
      }
    ]
  },
  {
    "name": "Amazon RedShift",
    "description": "data warehouse service, based on PostgreSQL",
    "abstract": "data warehouse service, based on PostgreSQL",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Amazon RedShift",
        "url": "http://aws.amazon.com/redshift/"
      }
    ]
  },
  {
    "name": "Amazon Simple Queue Service",
    "description": "fast, reliable, scalable, fully managed queue service",
    "abstract": "fast, reliable, scalable, fully managed queue service",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://aws.amazon.com/sqs/"
      }
    ]
  },
  {
    "name": "Amazon SimpleDB",
    "description": "a highly available and flexible non-relational data store that offloads the work of database administration",
    "abstract": "a highly available and flexible non-relational data store that offloads the work of database administration",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://aws.amazon.com/simpledb/"
      }
    ]
  },
  {
    "name": "AMPLAB Shark",
    "description": "Shark is a large-scale data warehouse system for Spark designed to be compatible with Apache Hive. It can execute Hive QL queries up to 100 times faster than Hive without any modification to the existing data or queries. Shark supports Hive's query language, metastore, serialization formats, and user-defined functions, providing seamless integration with existing Hive deployments and a familiar, more powerful option for new ones. Shark is built on top of Spark",
    "abstract": "data warehouse system for Spark",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "AMPLAB on GitHub Shark",
        "url": "https://github.com/amplab/shark/"
      }
    ]
  },
  {
    "name": "AMPLab SIMR",
    "description": "Apache Spark was developed thinking in Apache YARN. However, up to now, it has been relatively hard to run Apache Spark on Hadoop MapReduce v1 clusters, i.e. clusters that do not have YARN installed. Typically, users would have to get permission to install Spark/Scala on some subset of the machines, a process that could be time consuming. SIMR allows anyone with access to a Hadoop MapReduce v1 cluster to run Spark out of the box. A user can run Spark directly on top of Hadoop MapReduce v1 without any administrative rights, and without having Spark or Scala installed on any of the nodes.",
    "abstract": "run Spark on Hadoop MapReduce v1",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "SIMR on GitHub",
        "url": "http://databricks.github.io/simr/"
      }
    ]
  },
  {
    "name": "AMPLab Succinct",
    "description": "Enabling Queries on Compressed Data",
    "abstract": "Enabling Queries on Compressed Data",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://succinct.cs.berkeley.edu/wp/wordpress/"
      }
    ]
  },
  {
    "name": "Ankush",
    "description": "A big data cluster management tool that creates and manages clusters of different technologies.",
    "abstract": "A big data cluster management tool that creates and manages clusters of different technologies.",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/impetus-opensource/ankush"
      }
    ]
  },
  {
    "name": "Apache Accumulo",
    "description": "Distributed key/value store is a robust, scalable, high performance data storage and retrieval system. Apache Accumulo is based on Google's BigTable design and is built on top of Apache Hadoop, Zookeeper, and Thrift.  Accumulo is software created by the NSA with security features.",
    "abstract": "distribuited key/value store, built on Hadoop",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Apache Accumulo",
        "url": "http://accumulo.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Ambari",
    "description": "Intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs. Apache Ambari was donated by Hortonworks team to the ASF. It's a powerful and nice interface for Hadoop and other typical applications from the Hadoop ecosystem. Apache Ambari is under a heavy development, and it will incorporate new features in a near future. For example Ambari is able to deploy a complete Hadoop system from scratch, however is not possible use this GUI in a Hadoop system that is already running. The ability to provisioning the operating system could be a good addition, however probably is not in the roadmap..",
    "abstract": "operational framework for Hadoop mangement",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache Ambari",
        "url": "http://ambari.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Argus",
    "description": "framework to enable, monitor and manage comprehensive data security across the Hadoop platform",
    "abstract": "framework to enable, monitor and manage comprehensive data security across the Hadoop platform",
    "category": "Security",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://argus.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Aurora",
    "description": "is a service scheduler that runs on top of Apache Mesos",
    "abstract": "is a service scheduler that runs on top of Apache Mesos",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Apache Incubator",
        "url": "http://aurora.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Avro",
    "description": "Apache Avro is a framework for modeling, serializing and making Remote Procedure Calls (RPC). Avro data is described by a schema, and one interesting feature is that the schema is stored in the same file as the data it describes, so files are self-describing. Avro does not require code generation. This framework can compete with other similar tools like: Apache Thrift, Google Protocol Buffers, ZeroC ICE, and so on. ",
    "abstract": "data serialization system",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Avro",
        "url": "http://avro.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Bigtop",
    "description": "Bigtop was originally developed and released as an open source packaging infrastructure by Cloudera. BigTop is used for some vendors to build their own distributions based on Apache Hadoop (CDH, Pivotal HD, Intel's distribution), however Apache Bigtop does many more tasks, like continuous integration testing (with Jenkins, maven, ...) and is useful for packaging (RPM and DEB), deployment with Puppet, and so on. Apache Bigtop could be considered as a community effort with a main focus: put all bits of the Hadoop ecosystem as a whole, rather than individual projects.",
    "abstract": "system deployment framework for the Hadoop ecosystem",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache Bigtop.",
        "url": "http://bigtop.apache.org//"
      }
    ]
  },
  {
    "name": "Apache Blur",
    "description": "a search engine capable of querying massive amounts of structured data at incredible speeds",
    "abstract": "a search engine capable of querying massive amounts of structured data at incredible speeds",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://incubator.apache.org/blur/"
      }
    ]
  },
  {
    "name": "Apache BookKeeper",
    "description": "a distributed logging service called BookKeeper and a distributed publish/subscribe system built on top of BookKeeper called Hedwig",
    "abstract": "a distributed logging service called BookKeeper and a distributed publish/subscribe system built on top of BookKeeper called Hedwig",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://zookeeper.apache.org/bookkeeper/"
      }
    ]
  },
  {
    "name": "Apache Cassandra",
    "description": "Distributed Non-SQL DBMS, it’s a BDDB. MR can retrieve data from Cassandra. This BDDB can run without HDFS, or on-top of HDFS (DataStax fork of Cassandra).  HBase and its required supporting systems are derived from what is known of the original Google BigTable and Google File System designs (as known from the Google File System paper Google published in 2003, and the BigTable paper published in 2006). Cassandra on the other hand is a recent open source fork of a standalone database system initially coded by Facebook, which while implementing the BigTable data model, uses a system inspired by Amazon’s Dynamo for storing data (in fact much of the initial development work on Cassandra was performed by two Dynamo engineers recruited to Facebook from Amazon).",
    "abstract": "column-oriented distribuited datastore, inspired by BigTable",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Apache Cassandra",
        "url": "http://cassandra.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Chukwa",
    "description": "Large scale log aggregator, and analytics.",
    "abstract": "data collection system",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Apache Chukwa",
        "url": "http://incubator.apache.org/chukwa/"
      }
    ]
  },
  {
    "name": "Apache Crunch",
    "description": "is a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce. The APIs are especially useful when processing data that does not fit naturally into relational model, such as time series, serialized object formats like protocol buffers or Avro records, and HBase rows and columns. For Scala users, there is the Scrunch API, which is built on top of the Java APIs and includes a REPL (read-eval-print loop) for creating MapReduce pipelines.",
    "abstract": "a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://crunch.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Curator",
    "description": "Curator is a set of Java libraries that make using Apache ZooKeeper much easier.",
    "abstract": "Java libaries for Apache ZooKeeper",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://curator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache DataFu",
    "description": "DataFu provides a collection of Hadoop MapReduce jobs and functions in higher level languages based on it to perform data analysis. It provides functions for common statistics tasks (e.g. quantiles, sampling), PageRank, stream sessionization, and set and bag operations. DataFu also provides Hadoop jobs for incremental data processing in MapReduce. DataFu is a collection of Pig UDFs (including PageRank, sessionization, set operations, sampling, and much more) that were originally developed at LinkedIn.",
    "abstract": "collection of user-defined functions for Hadoop and Pig developed by LinkedIn",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "DataFu Apache Incubator",
        "url": "http://incubator.apache.org/projects/datafu.html"
      },
      {
        "text": "LinkedIn DataFu",
        "url": "https://github.com/linkedin/datafu"
      }
    ]
  },
  {
    "name": "Apache Drill",
    "description": "Drill is the open source version of Google's Dremel system which is available as an infrastructure service called Google BigQuery. In recent years open source systems have emerged to address the need for scalable batch processing (Apache Hadoop) and stream processing (Storm, Apache S4). Apache Hadoop, originally inspired by Google's internal MapReduce system, is used by thousands of organizations processing large-scale datasets. Apache Hadoop is designed to achieve very high throughput, but is not designed to achieve the sub-second latency needed for interactive data analysis and exploration. Drill, inspired by Google's internal Dremel system, is intended to address this need",
    "abstract": "framework for interactive analysis, inspired by Dremel",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Apache Drill",
        "url": "http://incubator.apache.org/drill/"
      }
    ]
  },
  {
    "name": "Apache Falcon",
    "description": "Apache™ Falcon is a data management framework for simplifying data lifecycle management and processing pipelines on Apache Hadoop®. It enables users to configure, manage and orchestrate data motion, pipeline processing, disaster recovery, and data retention workflows. Instead of hard-coding complex data lifecycle capabilities, Hadoop applications can now rely on the well-tested Apache Falcon framework for these functions. Falcon’s simplification of data management is quite useful to anyone building apps on Hadoop. Data Management on Hadoop encompasses data motion, process orchestration, lifecycle management, data discovery, etc. among other concerns that are beyond ETL. Falcon is a new data processing and management platform for Hadoop that solves this problem and creates additional opportunities by building on existing components within the Hadoop ecosystem (ex. Apache Oozie, Apache Hadoop DistCp etc.) without reinventing the wheel.",
    "abstract": "data management framework",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Apache Falcon",
        "url": "http://falcon.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Flink",
    "description": "high-performance runtime, and automatic program optimization",
    "abstract": "high-performance runtime, and automatic program optimization",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://flink.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Flume",
    "description": "Un-structured data agregator to HDFS.",
    "abstract": "service to manage large amount of log data",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Apache Flume",
        "url": "http://flume.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Giraph",
    "description": "Apache Giraph is an iterative graph processing system built for high scalability. For example, it is currently used at Facebook to analyze the social graph formed by users and their connections. Giraph originated as the open-source counterpart to Pregel, the graph processing architecture developed at Google",
    "abstract": "implementation of Pregel, based on Hadoop",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Apache Giraph",
        "url": "http://giraph.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Gora",
    "description": "framework for in-memory data model and persistence",
    "abstract": "framework for in-memory data model and persistence",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Gora",
        "url": "http://gora.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Hadoop",
    "description": "framework for distributed processing. Integrates MapReduce (parallel processing), YARN (job scheduling) and HDFS (distributed file system)",
    "abstract": "framework for distributed processing. Integrates MapReduce (parallel processing), YARN (job scheduling) and HDFS (distributed file system)",
    "category": "Frameworks",
    "tags": [],
    "links": [
      {
        "text": "Apache Hadoop",
        "url": "http://hadoop.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Hadoop Benchmarking",
    "description": "There are two main JAR files in Apache Hadoop for benchmarking. This JAR are micro-benchmarks for testing particular parts of the infrastructure, for instance TestDFSIO analyzes the disk system, TeraSort evaluates MapReduce tasks, WordCount measures cluster performance, etc. Micro-Benchmarks are packaged in the tests and exmaples JAR files, and you can get a list of them, with descriptions, by invoking the JAR file with no arguments. With regards Apache Hadoop 2.2.0 stable version we have available the following JAR files for test, examples and benchmarking. The Hadoop micro-benchmarks, are bundled in this JAR files: hadoop-mapreduce-examples-2.2.0.jar, hadoop-mapreduce-client-jobclient-2.2.0-tests.jar.",
    "abstract": "micro-benchmarks for testing Hadoop performances",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "MAPREDUCE-3561 umbrella ticket to track all the issues related to performance",
        "url": "https://issues.apache.org/jira/browse/MAPREDUCE-3561"
      }
    ]
  },
  {
    "name": "Apache Hama",
    "description": "Apache Top-Level open source project, allowing you to do advanced analytics beyond MapReduce. Many data analysis techniques such as machine learning and graph algorithms require iterative computations, this is where Bulk Synchronous Parallel model can be more effective than \"plain\" MapReduce.",
    "abstract": "BSP (Bulk Synchronous Parallel) computing framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Hama site",
        "url": "http://hama.apache.org/"
      }
    ]
  },
  {
    "name": "Apache HBase",
    "description": "Google BigTable Inspired. Non-relational distributed database. Ramdom, real-time r/w operations in column-oriented very large tables (BDDB: Big Data Data Base). It’s the backing system for MR jobs outputs. It’s the Hadoop database.  It’s for backing Hadoop MapReduce jobs with Apache HBase tables",
    "abstract": "column-oriented distribuited datastore, inspired by BigTable",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Apache HBase",
        "url": "http://hbase.apache.org/"
      }
    ]
  },
  {
    "name": "Apache HCatalog",
    "description": "HCatalog’s table abstraction presents users with a relational view of data in the Hadoop Distributed File System (HDFS) and ensures that users need not worry about where or in what format their data is stored. Right now HCatalog is part of Hive. Only old versions are separated for download.",
    "abstract": "table and storage management layer for Hadoop",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Apache HCatalog",
        "url": "http://hive.apache.org/docs/hcat_r0.5.0/"
      }
    ]
  },
  {
    "name": "Apache HDFS",
    "description": "The Hadoop Distributed File System (HDFS) offers a way to store large files across \nmultiple machines. Hadoop and HDFS was derived from Google File System (GFS) paper. \nPrior to Hadoop 2.0.0, the NameNode was a single point of failure (SPOF) in an HDFS cluster. \nWith Zookeeper the HDFS High Availability feature addresses this problem by providing \nthe option of running two redundant NameNodes in the same cluster in an Active/Passive \nconfiguration with a hot standby. ",
    "abstract": "a way to store large files across multiple machines",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "hadoop.apache.org",
        "url": "http://hadoop.apache.org/"
      },
      {
        "text": "Google FileSystem - GFS Paper",
        "url": "http://research.google.com/archive/gfs.html"
      },
      {
        "text": "Cloudera Why HDFS",
        "url": "http://blog.cloudera.com/blog/2012/07/why-we-build-our-platform-on-hdfs/"
      },
      {
        "text": "Hortonworks Why HDFS",
        "url": "http://hortonworks.com/blog/thinking-about-the-hdfs-vs-other-storage-technologies/"
      }
    ]
  },
  {
    "name": "Apache Helix",
    "description": "Apache Helix is a generic cluster management framework used for the automatic management of partitioned, replicated and distributed resources hosted on a cluster of nodes. Originally developed by Linkedin, now is in an incubator project at Apache. Helix is developed on top of Zookeeper for coordination tasks. .",
    "abstract": "cluster management framework",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache Helix",
        "url": "http://helix.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Hive",
    "description": "Data Warehouse infrastructure developed by Facebook. Data summarization, query, and analysis. It’s provides SQL-like language (not SQL92 compliant): HiveQL.",
    "abstract": "SQL-like data warehouse system for Hadoop",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Apache Hive",
        "url": "http://hive.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Kafka",
    "description": "Distributed publish-subscribe system for processing large amounts of streaming data. Kafka is a Message Queue developed by LinkedIn that persists messages to disk in a very performant manner. Because messages are persisted, it has the interesting ability for clients to rewind a stream and consume the messages again. Another upside of the disk persistence is that bulk importing the data into HDFS for offline analysis can be done very quickly and efficiently. Storm, developed by BackType (which was acquired by Twitter a year ago), is more about transforming a stream of messages into new streams.",
    "abstract": "distributed publish-subscribe messaging system",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Apache Kafka",
        "url": "http://kafka.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Karaf",
    "description": "Apache Karaf is an OSGi runtime that runs on top of any OSGi framework and provides you a set of services, a powerful provisioning concept, an extensible shell &amp; more.",
    "abstract": "OSGi runtime that runs on top of any OSGi framework",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://karaf.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Kiji",
    "description": "Build Real-time Big Data Applications on Apache HBase.",
    "abstract": "framework to collect and analyze data in real-time, based on HBase",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.kiji.org/"
      }
    ]
  },
  {
    "name": "Apache Knox Gateway",
    "description": " System that provides a single point of secure access for Apache Hadoop clusters. The goal is to simplify Hadoop security for both users (i.e. who access the cluster data and execute jobs) and operators (i.e. who control access and manage the cluster). The Gateway runs as a server (or cluster of servers) that serve one or more Hadoop clusters.",
    "abstract": "single point of secure access for Hadoop clusters",
    "category": "Security",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://knox.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Lucene",
    "description": "Search engine library",
    "abstract": "Search engine library",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Apache Lucene",
        "url": "http://lucene.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Mahout",
    "description": "Machine learning library and math library, on top of MapReduce.",
    "abstract": "machine learning library for Hadoop",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Apache Mahout",
        "url": "http://mahout.apache.org/"
      }
    ]
  },
  {
    "name": "Apache MapReduce",
    "description": "MapReduce is a programming model for processing large data sets with a parallel, distributed algorithm on a cluster. Apache MapReduce was derived from Google MapReduce: Simplified Data Processing on Large Clusters paper. The current Apache MapReduce version is built over Apache YARN Framework. YARN stands for “Yet-Another-Resource-Negotiator”. It is a new framework that facilitates writing arbitrary distributed processing frameworks and applications. YARN’s execution model is more generic than the earlier MapReduce implementation. YARN can run applications that do not follow the MapReduce model, unlike the original Apache Hadoop MapReduce (also called MR1). Hadoop YARN is an attempt to take Apache Hadoop beyond MapReduce for data-processing.",
    "abstract": "programming model for processing large data sets with a parallel, distributed algorithm on a cluster",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache MapReduce",
        "url": "http://wiki.apache.org/hadoop/MapReduce/"
      },
      {
        "text": "Google MapReduce paper",
        "url": "http://research.google.com/archive/mapreduce.html"
      },
      {
        "text": "Writing YARN applications",
        "url": "http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html"
      }
    ]
  },
  {
    "name": "Apache Mesos",
    "description": "Mesos is a cluster manager that provides resource sharing and isolation across cluster applications. Like HTCondor, SGE or Troque can do it. However Mesos is hadoop centred design",
    "abstract": "cluster manager",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache Mesos",
        "url": "http://mesos.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Nutch",
    "description": "Highly extensible and scalable open source web crawler software project. A search engine based on Lucene: A Web crawler is an Internet bot that systematically browses the World Wide Web, typically for the purpose of Web indexing. Web crawlers can copy all the pages they visit for later processing by a search engine that indexes the downloaded pages so that users can search them much more quickly.",
    "abstract": "open source web crawler",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://nutch.apache.org/"
      }
    ]
  },
  {
    "name": "Apache OODT",
    "description": "OODT was originally developed at NASA Jet Propulsion Laboratory to support capturing, processing and sharing of data for NASA's scientific archives",
    "abstract": "capturing, processing and sharing of data for NASA's scientific archives",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://oodt.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Oozie",
    "description": "Workflow scheduler system for MR jobs using DAGs (Direct Acyclical Graphs). Oozie Coordinator can trigger jobs by time (frequency) and data availabilit",
    "abstract": "workflow job scheduler",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Apache Oozie",
        "url": "http://oozie.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Optiq",
    "description": "framework that allows efficient translation of queries involving heterogeneous and federated data",
    "abstract": "framework that allows efficient translation of queries involving heterogeneous and federated data",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://wiki.apache.org/incubator/OptiqProposal"
      }
    ]
  },
  {
    "name": "Apache Phoenix",
    "description": "Apache Phoenix is a SQL skin over HBase delivered as a client-embedded JDBC driver targeting low latency queries over HBase data. Apache Phoenix takes your SQL query, compiles it into a series of HBase scans, and orchestrates the running of those scans to produce regular JDBC result sets. The table metadata is stored in an HBase table and versioned, such that snapshot queries over prior versions will automatically use the correct schema. Direct use of the HBase API, along with coprocessors and custom filters, results in performance on the order of milliseconds for small queries, or seconds for tens of millions of rows.",
    "abstract": "SQL skin over HBase",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Apache Phoenix site",
        "url": "http://phoenix.incubator.apache.org/index.html"
      }
    ]
  },
  {
    "name": "Apache Pig",
    "description": "Pig provides an engine for executing data flows in parallel on Hadoop. It includes a language, Pig Latin, for expressing these data flows. Pig Latin includes operators for many of the traditional data operations (join, sort, filter, etc.), as well as the ability for users to develop their own functions for reading, processing, and writing data. Pig runs on Hadoop. It makes use of both the Hadoop Distributed File System, HDFS, and Hadoop’s processing system, MapReduce. ",
    "abstract": "high level language to express data analysis programs for Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "pig.apache.org/",
        "url": "https://pig.apache.org/"
      },
      {
        "text": "Pig examples by Alan Gates",
        "url": "https://github.com/alanfgates/programmingpig"
      }
    ]
  },
  {
    "name": "Apache Qpid",
    "description": "messaging tools that speak AMQP and support many languages and platforms",
    "abstract": "messaging tools that speak AMQP and support many languages and platforms",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://qpid.apache.org/"
      }
    ]
  },
  {
    "name": "Apache S4",
    "description": "S4 is a general-purpose, distributed, scalable, fault-tolerant, pluggable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data.",
    "abstract": "framework for stream processing, implementation of S4",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache S4",
        "url": "http://incubator.apache.org/s4/"
      }
    ]
  },
  {
    "name": "Apache Samza",
    "description": "Apache Samza is a distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management. Developed by http://www.linkedin.com/in/jaykreps Linkedin.",
    "abstract": "stream processing framework, based on Kafla and YARN",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Apache Samza",
        "url": "http://samza.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Sentry",
    "description": "Sentry is the next step in enterprise-grade big data security and delivers fine-grained authorization to data stored in Apache Hadoop™. An independent security module that integrates with open source SQL query engines Apache Hive and Cloudera Impala, Sentry delivers advanced authorization controls to enable multi-user applications and cross-functional processes for enterprise data sets. Sentry was a Cloudera development.",
    "abstract": "security module for data stored in Hadoop",
    "category": "Security",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://incubator.apache.org/projects/sentry.html"
      }
    ]
  },
  {
    "name": "Apache Slider",
    "description": "Slider is a YARN application to deploy existing distributed applications on YARN, monitor them and make them larger or smaller as desired -even while the cluster is running.",
    "abstract": "is a YARN application to deploy existing distributed applications on YARN",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Gihub page",
        "url": "https://github.com/hortonworks/slider"
      }
    ]
  },
  {
    "name": "Apache Solr",
    "description": "Search platform for Apache Lucene",
    "abstract": "Search platform for Apache Lucene",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Apache Solr",
        "url": "http://lucene.apache.org/solr/"
      }
    ]
  },
  {
    "name": "Apache Spark",
    "description": "Data analytics cluster computing framework originally developed in the AMPLab at UC Berkeley. Spark fits into the Hadoop open-source community, building on top of the Hadoop Distributed File System (HDFS). However, Spark provides an easier to use alternative to Hadoop MapReduce and offers performance up to 10 times faster than previous generation systems like Hadoop MapReduce for certain applications.",
    "abstract": "framework for in-memory cluster computing",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Incubator Spark",
        "url": "http://spark.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Spark Bagel",
    "description": "implementation of Pregel, part of Spark",
    "abstract": "implementation of Pregel, part of Spark",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Apache Spark Bagel",
        "url": "http://spark.incubator.apache.org/docs/0.7.3/bagel-programming-guide.html"
      }
    ]
  },
  {
    "name": "Apache Spark Streaming",
    "description": "framework for stream processing, part of Spark",
    "abstract": "framework for stream processing, part of Spark",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Spark Streaming",
        "url": "http://spark.incubator.apache.org/docs/0.7.3/streaming-programming-guide.html"
      }
    ]
  },
  {
    "name": "Apache Sqoop",
    "description": "System for bulk data transfer between HDFS and structured datastores as RDBMS. Like Flume but from HDFS to RDBMS.",
    "abstract": "tool to transfer data between Hadoop and a structured datastore",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Apache Sqoop",
        "url": "http://sqoop.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Storm",
    "description": "Storm is a complex event processor and distributed computation framework written predominantly in the Clojure programming language. Is a distributed real-time computation system for processing fast, large streams of data. Storm is an architecture based on master-workers paradigma. So a Storm cluster mainly consists of a master and worker nodes, with coordination done by Zookeeper. ",
    "abstract": "framework for stream processing by Twitter also on YARN",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Storm Project/",
        "url": "http://storm-project.net/"
      },
      {
        "text": "Storm-on-YARN",
        "url": "github.com/yahoo/storm-yarn"
      }
    ]
  },
  {
    "name": "Apache Tez",
    "description": "Tez is a proposal to develop a generic application which can be used to process complex data-processing task DAGs and runs natively on Apache Hadoop YARN.",
    "abstract": "application framework for executing a complex DAG (directed acyclic graph) of tasks, built on YARN",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Tez",
        "url": "http://tez.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Thrift",
    "description": "A cross-language RPC framework for service creations. It’s the service base for Facebook technologies (the original Thrift contributor). Thrift provides a framework for developing and accessing remote services. It allows developers to create services that can be consumed by any application that is written in a language that there are Thrift bindings for. Thrift manages serialization of data to and from a service, as well as the protocol that describes a method invocation, response, etc. Instead of writing all the RPC code -- you can just get straight to your service logic. Thrift uses TCP and so a given service is bound to a particular port.",
    "abstract": "framework to build binary protocols",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Thrift",
        "url": "http://thrift.apache.org//"
      }
    ]
  },
  {
    "name": "Apache Tika",
    "description": "Toolkit detects and extracts metadata and structured text content from various documents using existing parser libraries.",
    "abstract": "content analysis toolkit",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Apache Tika",
        "url": "https://tika.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Twill",
    "description": "Twill is an abstraction over Apache Hadoop® YARN that reduces the complexity of developing distributed applications, allowing developers to focus more on their business logic. Twill uses a simple thread-based model that Java programmers will find familiar. YARN can be viewed as a compute fabric of a cluster, which means YARN applications like Twill will run on any Hadoop 2 cluster.",
    "abstract": "abstraction over YARN that reduces the complexity of developing distributed applications",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Twill Incubator",
        "url": "https://incubator.apache.org/projects/twill.html"
      }
    ]
  },
  {
    "name": "Apache UIMA",
    "description": "Unstructured Information Management applications are software systems that analyze large volumes of unstructured information in order to discover knowledge that is relevant to an end user",
    "abstract": "Unstructured Information Management applications are software systems that analyze large volumes of unstructured information in order to discover knowledge that is relevant to an end user",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://uima.apache.org/"
      }
    ]
  },
  {
    "name": "Apache Whirr",
    "description": "Apache Whirr is a set of libraries for running cloud services. It allows you to use simple commands to boot clusters of distributed systems for testing and experimentation. Apache Whirr makes booting clusters easy.",
    "abstract": "set of libraries for running cloud services",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache Whirr",
        "url": "http://whirr.apache.org/"
      }
    ]
  },
  {
    "name": "Apache YARN",
    "description": "Apache Hadoop YARN is a sub-project of Hadoop at the Apache Software Foundation introduced in Hadoop 2.0 that separates the resource management and processing components. YARN was born of a need to enable a broader array of interaction patterns for data stored in HDFS beyond MapReduce. The YARN-based architecture of Hadoop 2.0 provides a more general processing platform that is not constrained to MapReduce.",
    "abstract": "Cluster manager",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Apache YARN",
        "url": "http://hortonworks.com/hadoop/yarn/"
      }
    ]
  },
  {
    "name": "Apache Zookeeper",
    "description": "It’s a coordination service that gives you the tools you need to write correct distributed applications. ZooKeeper was developed at Yahoo! Research. Several Hadoop projects are already using ZooKeeper to coordinate the cluster and provide highly-available distributed services. Perhaps most famous of those are Apache HBase, Storm, Kafka. ZooKeeper is an application library with two principal implementations of the APIs—Java and C—and a service component implemented in Java that runs on an ensemble of dedicated servers. Zookeeper is for building distributed systems, simplifies the development process, making it more agile and enabling more robust implementations. Back in 2006, Google published a paper on \"Chubby\", a distributed lock service which gained wide adoption within their data centers. Zookeeper, not surprisingly, is a close clone of Chubby designed to fulfill many of the same roles for HDFS and other Hadoop infrastructure.",
    "abstract": "centralized service for process management",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Apache Zookeeper",
        "url": "http://zookeeper.apache.org/"
      },
      {
        "text": "Google Chubby paper",
        "url": "http://research.google.com/archive/chubby.html"
      }
    ]
  },
  {
    "name": "Apama analytics",
    "description": "platform for streaming analytics and intelligent automated action",
    "abstract": "platform for streaming analytics and intelligent automated action",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.softwareag.com/corporate/products/bigdata/apama_analytics/overview/"
      }
    ]
  },
  {
    "name": "Apollo",
    "description": "ActiveMQ's next generation of messaging",
    "abstract": "ActiveMQ's next generation of messaging",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://activemq.apache.org/apollo/"
      }
    ]
  },
  {
    "name": "ArangoDB",
    "description": "An open-source database with a flexible data model for documents, graphs, and key-values. Build high performance applications using a convenient sql-like query language or JavaScript extensions.",
    "abstract": "multi model distribuited database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "ArangoDB site",
        "url": "https://www.arangodb.org/"
      }
    ]
  },
  {
    "name": "Arbor",
    "description": "graph visualization library using web workers and jQuery.",
    "abstract": "graph visualization library using web workers and jQuery",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/samizdatco/arbor"
      }
    ]
  },
  {
    "name": "Atigeo xPatterns",
    "description": "data analytics platform",
    "abstract": "data analytics platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://xpatterns.com/"
      }
    ]
  },
  {
    "name": "Ayasdi Core",
    "description": "tool for topological data analysis",
    "abstract": "tool for topological data analysis",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ayasdi.com/"
      }
    ]
  },
  {
    "name": "BayesDB",
    "description": "BayesDB, a Bayesian database table, lets users query the probable implications of their tabular data as easily as an SQL database lets them query the data itself. Using the built-in Bayesian Query Language (BQL), users with no statistics training can solve basic data science problems, such as detecting predictive relationships between variables, inferring missing values, simulating probable observations, and identifying statistically similar database entries.",
    "abstract": "statistic oriented SQL database",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "BayesDB site",
        "url": "http://probcomp.csail.mit.edu/bayesdb/index.html"
      }
    ]
  },
  {
    "name": "Beanstalkd",
    "description": "simple, fast work queue",
    "abstract": "simple, fast work queue",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://kr.github.io/beanstalkd/"
      }
    ]
  },
  {
    "name": "BeeGFS",
    "description": "formerly FhGFS, parallel distributed file system",
    "abstract": "formerly FhGFS, parallel distributed file system",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.fhgfs.com/cms/"
      }
    ]
  },
  {
    "name": "Berkeley SWIM Benchmark",
    "description": "The SWIM benchmark (Statistical Workload Injector for MapReduce), is a benchmark representing a real-world big data workload developed by University of California at Berkley in close cooperation with Facebook. This test provides rigorous measurements of the performance of MapReduce systems comprised of real industry workloads.",
    "abstract": "real-world big data workload benchmark",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "GitHub SWIN",
        "url": "https://github.com/SWIMProjectUCB/SWIM/wiki"
      }
    ]
  },
  {
    "name": "BerkeleyDB",
    "description": "a software library that provides a high-performance embedded database for key/value data",
    "abstract": "a software library that provides a high-performance embedded database for key/value data",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Oracle website",
        "url": "http://www.oracle.com/us/products/database/berkeley-db/overview/index.html"
      }
    ]
  },
  {
    "name": "Big-Bench",
    "description": "Big Bench Workload Development",
    "abstract": "Big Bench Workload Development",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/intel-hadoop/Big-Bench"
      }
    ]
  },
  {
    "name": "BIME Analytics",
    "description": "business intelligence platform in the cloud",
    "abstract": "business intelligence platform in the cloud",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.bimeanalytics.com/"
      }
    ]
  },
  {
    "name": "Bit.ly NSQ",
    "description": "realtime distributed message processing at scale",
    "abstract": "realtime distributed message processing at scale",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/bitly/nsq"
      }
    ]
  },
  {
    "name": "BlinkDB",
    "description": "massively parallel, approximate query engine",
    "abstract": "massively parallel, approximate query engine",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "BlinkDB",
        "url": "http://blinkdb.org/"
      }
    ]
  },
  {
    "name": "Box Tron",
    "description": "proxy to memcached servers",
    "abstract": "proxy to memcached servers",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.opendns.com/2014/09/16/caching-scale/"
      }
    ]
  },
  {
    "name": "brain",
    "description": "Neural networks in JavaScript.",
    "abstract": "Neural networks in JavaScript",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/harthur/brain"
      }
    ]
  },
  {
    "name": "Brooklyn",
    "description": "brooklyn is a library that simplifies application deployment and management.\nFor deployment, it is designed to tie in with other tools, giving single-click deploy and adding the concepts of manageable clusters and fabrics:\nMany common software entities available out-of-the-box.\nIntegrates with Apache Whirr -- and thereby Chef and Puppet -- to deploy well-known services such as Hadoop and elasticsearch (or use POBS, plain-old-bash-scripts)\nUse PaaS's such as OpenShift, alongside self-built clusters, for maximum flexibility",
    "abstract": "library that simplifies application deployment and management",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "http://brooklyncentral.github.io/"
      }
    ]
  },
  {
    "name": "Buildoop",
    "description": "Buildoop is an open source project licensed under Apache License 2.0, based on Apache BigTop idea. Buildoop is a collaboration project that provides templates and tools to help you create custom Linux-based systems based on Hadoop ecosystem. The project is built from scrach using Groovy language, and is not based on a mixture of tools like BigTop does (Makefile, Gradle, Groovy, Maven), probably is easier to programming than BigTop, and the desing is focused in the basic ideas behind the buildroot Yocto Project. The project is in early stages of development right now.",
    "abstract": "Similar to Apache BigTop based on Groovy language",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Buildoop",
        "url": "http://buildoop.github.io/"
      }
    ]
  },
  {
    "name": "C-Store",
    "description": "column oriented DBMS",
    "abstract": "column oriented DBMS",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://db.lcs.mit.edu/projects/cstore/"
      }
    ]
  },
  {
    "name": "C3",
    "description": "D3-based reusable chart library",
    "abstract": "D3-based reusable chart library",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://c3js.org/"
      }
    ]
  },
  {
    "name": "CartoDB",
    "description": "open-source or freemium hosting for geospatial databases with powerful front-end editing capabilities and a robust API",
    "abstract": "open-source or freemium hosting for geospatial databases with powerful front-end editing capabilities and a robust API",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/CartoDB/cartodb"
      }
    ]
  },
  {
    "name": "Cascalog",
    "description": "data processing and querying library",
    "abstract": "data processing and querying library",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Cascalog",
        "url": "http://cascalog.org/"
      }
    ]
  },
  {
    "name": "Celery",
    "description": "Distributed Task Queue",
    "abstract": "Distributed Task Queue",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.celeryproject.org/"
      }
    ]
  },
  {
    "name": "Ceph Filesystem",
    "description": "Ceph is a free software storage platform designed to present object, block, \nand file storage from a single distributed computer cluster. Ceph's main \ngoals are to be completely distributed without a single point of failure, \nscalable to the exabyte level, and freely-available. The data is replicated, \nmaking it fault tolerant. The problem right now is Ceph currently requires Hadoop 1.1.X stable series.",
    "abstract": "software storage platform designed",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Ceph Filesystem site",
        "url": "http://ceph.com/ceph-storage/file-system/"
      },
      {
        "text": "Ceph and Hadoop",
        "url": "http://ceph.com/docs/next/cephfs/hadoop/"
      },
      {
        "text": "HADOOP-6253",
        "url": "https://issues.apache.org/jira/browse/HADOOP-6253"
      }
    ]
  },
  {
    "name": "Chart.js",
    "description": "open source HTML5 Charts visualizations.",
    "abstract": "open source HTML5 Charts visualizations",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.chartjs.org/"
      }
    ]
  },
  {
    "name": "Chartio",
    "description": "lean business intelligence platform to visualize and explore your data.",
    "abstract": "lean business intelligence platform to visualize and explore your data",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://chartio.com"
      }
    ]
  },
  {
    "name": "Chartist.js",
    "description": "another open source HTML5 Charts visualization",
    "abstract": "another open source HTML5 Charts visualization",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/gionkunz/chartist-js"
      }
    ]
  },
  {
    "name": "Cheetah",
    "description": "High Performance, Custom Data Warehouse on Top of MapReduce",
    "abstract": "High Performance, Custom Data Warehouse on Top of MapReduce",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Paper",
        "url": "http://vldbarc.org/pvldb/vldb2010/pvldb_vol3/I08.pdf"
      }
    ]
  },
  {
    "name": "Chronos",
    "description": "distributed and fault-tolerant scheduler",
    "abstract": "distributed and fault-tolerant scheduler",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Chronos",
        "url": "http://airbnb.github.io/chronos/"
      }
    ]
  },
  {
    "name": "Cloudera Director",
    "description": "a comprehensive data management platform with the flexibility and power to evolve with your business",
    "abstract": "a comprehensive data management platform with the flexibility and power to evolve with your business",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.cloudera.com/content/cloudera/en/products-and-services/director.html"
      }
    ]
  },
  {
    "name": "Cloudera HUE",
    "description": "Web application for interacting with Apache Hadoop.",
    "abstract": "web application for interacting with Hadoop",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://gethue.com/"
      }
    ]
  },
  {
    "name": "Cloudera Impala",
    "description": "The Apache-licensed Impala project brings scalable parallel database technology to Hadoop, enabling users to issue low-latency SQL queries to data stored in HDFS and Apache HBase without requiring data movement or transformation. It's a Google Dremel clone (Big Query google).",
    "abstract": "framework for interactive analysis, Inspired by Dremel",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html"
      },
      {
        "text": "Cloudera Impala",
        "url": "http://www.cloudera.com/content/cloudera/en/products/cdh/impala.html"
      }
    ]
  },
  {
    "name": "Cloudera Morphlines",
    "description": "framework that help ETL to Solr, HBase and HDFS.",
    "abstract": "framework that help ETL to Solr, HBase and HDFS",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/cloudera/cdk/tree/master/cdk-morphlines"
      }
    ]
  },
  {
    "name": "Cloudera Oryx",
    "description": "The Oryx open source project provides simple, real-time large-scale machine learning / predictive analytics infrastructure. It implements a few classes of algorithm commonly used in business applications: collaborative filtering / recommendation, classification / regression, and clustering.",
    "abstract": "real-time large-scale machine learning",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Oryx at GitHub",
        "url": "https://github.com/cloudera/oryx"
      },
      {
        "text": "Cloudera forum for Machine Learning",
        "url": "https://community.cloudera.com/t5/Data-Science-and-Machine/bd-p/Mahout"
      }
    ]
  },
  {
    "name": "Clusterpoint",
    "description": "a database software for high-speed storage and large-scale processing of XML and JSON data on clusters of commodity hardware",
    "abstract": "a database software for high-speed storage and large-scale processing of XML and JSON data on clusters of commodity hardware",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.clusterpoint.com/"
      }
    ]
  },
  {
    "name": "Cockroach",
    "description": "Scalable, Geo-Replicated, Transactional Datastore",
    "abstract": "Scalable, Geo-Replicated, Transactional Datastore",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/cockroachdb/cockroach"
      }
    ]
  },
  {
    "name": "Concurrent Cascading",
    "description": "Application framework for Java developers to simply develop robust Data Analytics and Data Management applications on Apache Hadoop.",
    "abstract": "framework for data management/analytics on Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Cascanding",
        "url": "http://www.cascading.org/"
      }
    ]
  },
  {
    "name": "Concurrent Lingual",
    "description": "Open source project enabling fast and simple Big Data application development on Apache Hadoop.  project that delivers ANSI-standard SQL technology to easily build new and integrate existing applications onto Hadoop",
    "abstract": "SQL-like query language for Cascading",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Cascading Lingual",
        "url": "http://www.cascading.org/lingual/"
      }
    ]
  },
  {
    "name": "Concurrent Pattern",
    "description": "Machine Learning for Cascading on Apache Hadoop through an API, and standards based PMML",
    "abstract": "machine learning library for Cascading",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Cascading Pattern",
        "url": "http://www.cascading.org/pattern/"
      }
    ]
  },
  {
    "name": "convnetjs",
    "description": "Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser.",
    "abstract": "Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/karpathy/convnetjs"
      }
    ]
  },
  {
    "name": "Couchbase ForestDB",
    "description": "Fast Key-Value Storage Engine Based on Hierarchical B+-Tree Trie",
    "abstract": "Fast Key-Value Storage Engine Based on Hierarchical B+-Tree Trie",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/couchbaselabs/forestdb"
      }
    ]
  },
  {
    "name": "Crate Data",
    "description": "is an open source massively scalable data store. It requires zero administration.",
    "abstract": "is an open source massively scalable data store. It requires zero administration",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://crate.io/"
      }
    ]
  },
  {
    "name": "Crossfilter",
    "description": "avaScript library for exploring large multivariate datasets in the browser. Works well with dc.js and d3.js",
    "abstract": "avaScript library for exploring large multivariate datasets in the browser. Works well with dc.js and d3.js",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://square.github.io/crossfilter/"
      }
    ]
  },
  {
    "name": "Crossroads I/O",
    "description": "library for building scalable and high performance distributed applications",
    "abstract": "library for building scalable and high performance distributed applications",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.crossroads.io/"
      }
    ]
  },
  {
    "name": "Cube",
    "description": "uses MongoDB to store time series data",
    "abstract": "uses MongoDB to store time series data",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://square.github.io/cube/"
      }
    ]
  },
  {
    "name": "Cubism",
    "description": "JavaScript library for time series visualization.",
    "abstract": "JavaScript library for time series visualization",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/square/cubism"
      }
    ]
  },
  {
    "name": "cuDNN",
    "description": "GPU-accelerated library of primitives for deep neural networks",
    "abstract": "GPU-accelerated library of primitives for deep neural networks",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://devblogs.nvidia.com/parallelforall/accelerate-machine-learning-cudnn-deep-neural-network-library/"
      }
    ]
  },
  {
    "name": "Cytoscape",
    "description": "open source software platform for visualizing complex networks and integrating these with any type of attribute data",
    "abstract": "JavaScript library for visualizing complex networks",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://cytoscape.github.io/"
      },
      {
        "text": "Website",
        "url": "http://www.cytoscape.org/"
      }
    ]
  },
  {
    "name": "D3",
    "description": "javaScript library for manipulating documents.",
    "abstract": "javaScript library for manipulating documents",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://d3js.org/"
      }
    ]
  },
  {
    "name": "Damballa Parkour",
    "description": "Library for develop MapReduce programs using the LISP like language Clojure. Parkour aims to provide deep Clojure integration for Hadoop.  Programs using Parkour are normal Clojure programs, using standard Clojure functions instead of new framework abstractions.  Programs using Parkour are also full Hadoop programs, with complete access to absolutely everything possible in raw Java Hadoop MapReduce.",
    "abstract": "MapReduce library for Clojure",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Parkour GitHub Project",
        "url": "https://github.com/damballa/parkour"
      }
    ]
  },
  {
    "name": "Darner",
    "description": "simple, lightweight message queue",
    "abstract": "simple, lightweight message queue",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/wavii/darner"
      }
    ]
  },
  {
    "name": "Datapine",
    "description": "self-service business intelligence tool in the cloud",
    "abstract": "self-service business intelligence tool in the cloud",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.datapine.com/"
      }
    ]
  },
  {
    "name": "Datasalt Pangool",
    "description": "A new MapReduce paradigm. A new API for MR jobs, in higher level than Java.",
    "abstract": "alternative MapReduce paradigm",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/datasalt/pangool"
      }
    ]
  },
  {
    "name": "Datasalt Splout SQL",
    "description": "Splout allows serving an arbitrarily big dataset with high QPS rates and at the same time provides full SQL query syntax.",
    "abstract": "full SQL query engine for big datasets",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.datasalt.com/products/splout-sql/"
      }
    ]
  },
  {
    "name": "DataTorrent StrAM",
    "description": "real-time engine is designed to enable distributed, asynchronous, real time in-memory big-data computations in as unblocked a way as possible, with minimal overhead and impact on performance.",
    "abstract": "real-time engine is designed to enable distributed, asynchronous, real time in-memory big-data computations in as unblocked a way as possible, with minimal overhead and impact on performance",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.datatorrent.com/"
      }
    ]
  },
  {
    "name": "Datomic",
    "description": "distributed database designed to enable scalable, flexible and intelligent applications.",
    "abstract": "distributed database designed to enable scalable, flexible and intelligent applications",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.datomic.com/"
      }
    ]
  },
  {
    "name": "DC.js",
    "description": "Dimensional charting built to work natively with crossfilter rendered using d3.js. Excellent for connecting charts/additional metadata to hover events in D3",
    "abstract": "Dimensional charting built to work natively with crossfilter rendered using d3.js. Excellent for connecting charts/additional metadata to hover events in D3",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://dc-js.github.io/dc.js/"
      }
    ]
  },
  {
    "name": "Decider",
    "description": "Flexible and Extensible Machine Learning in Ruby.",
    "abstract": "Flexible and Extensible Machine Learning in Ruby",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/danielsdeleo/Decider"
      }
    ]
  },
  {
    "name": "Deimos",
    "description": "Mesos containerizer hooks for Docker",
    "abstract": "Mesos containerizer hooks for Docker",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/mesosphere/deimos"
      }
    ]
  },
  {
    "name": "Develoop",
    "description": "tool for provisioning, managing and monitoring Apache Hadoop",
    "abstract": "tool for provisioning, managing and monitoring Apache Hadoop",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://deploop.github.io/"
      }
    ]
  },
  {
    "name": "Disco DDFS",
    "description": "distributed filesystem",
    "abstract": "distributed filesystem",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://disco.readthedocs.org/en/latest/howto/ddfs.html"
      }
    ]
  },
  {
    "name": "DistributedR",
    "description": "scalable high-performance platform for the R language",
    "abstract": "scalable high-performance platform for the R language",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.vertica.com/distributedr/"
      }
    ]
  },
  {
    "name": "Docker",
    "description": "an open platform for developers and sysadmins to build, ship, and run distributed applications",
    "abstract": "an open platform for developers and sysadmins to build, ship, and run distributed applications",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.docker.com/"
      }
    ]
  },
  {
    "name": "Domino",
    "description": "Run, scale, share, and deploy models Ñ without any infrastructure.",
    "abstract": "Run, scale, share, and deploy models Ñ without any infrastructure.",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.dominoup.com/"
      }
    ]
  },
  {
    "name": "Drizzle",
    "description": "Drizzle is a re-designed version of the MySQL v6.0 codebase and is designed around a central concept of having a microkernel architecture. Features such as the query cache and authentication system are now plugins to the database, which follow the general theme of \"pluggable storage engines\" that were introduced in MySQL 5.1. It supports PAM, LDAP, and HTTP AUTH for authentication via plugins it ships. Via its plugin system it currently supports logging to files, syslog, and remote services such as RabbitMQ and Gearman. Drizzle is an ACID-compliant relational database that supports transactions via an MVCC design",
    "abstract": "evolution of MySQL 6.0",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.drizzle.org/"
      }
    ]
  },
  {
    "name": "Drools",
    "description": "a Business Rules Management System (BRMS) solution",
    "abstract": "a Business Rules Management System (BRMS) solution",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.drools.org/"
      }
    ]
  },
  {
    "name": "eBay Kylin",
    "description": "Distributed Analytics Engine from eBay Inc. that provides SQL interface and multi-dimensional analysis (OLAP) on Hadoop supporting extremely large datasets",
    "abstract": "Distributed Analytics Engine from eBay Inc. that provides SQL interface and multi-dimensional analysis (OLAP) on Hadoop supporting extremely large datasets",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.kylin.io/"
      }
    ]
  },
  {
    "name": "eBay Oink",
    "description": "REST based interface for PIG execution",
    "abstract": "REST based interface for PIG execution",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/eBay/oink"
      },
      {
        "text": "Website",
        "url": "http://www.ebaytechblog.com/2014/07/22/oink-making-pig-self-service/"
      }
    ]
  },
  {
    "name": "Eclipse BIRT",
    "description": "BIRT is an open source Eclipse-based reporting system that integrates with your Java/Java EE application to produce compelling reports.",
    "abstract": "Eclipse-based reporting system",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.eclipse.org/birt/"
      }
    ]
  },
  {
    "name": "Edis",
    "description": "Edis is a protocol-compatible Server replacement for Redis, written in Erlang. Edis's goal is to be a drop-in replacement for Redis when persistence is more important than holding the dataset in-memory. Edis (currently) uses Google's leveldb as a backend. Future plans call for a multi-master clustering model. Near term goals are to act as a read-slave for existing Redis servers.",
    "abstract": "is a protocol-compatible Server replacement for Redis",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://inaka.github.io/edis/"
      }
    ]
  },
  {
    "name": "ElasticSearch",
    "description": "Search and analytics engine based on Apache Lucene",
    "abstract": "Search and analytics engine based on Apache Lucene",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "ElasticSearch",
        "url": "http://www.elasticsearch.org/"
      }
    ]
  },
  {
    "name": "Elasticsearch Hadoop",
    "description": "Elasticsearch real-time search and analytics natively integrated with Hadoop. Supports Map/Reduce, Cascading, Apache Hive and Apache Pig.",
    "abstract": "Elasticsearch real-time search and analytics natively integrated with Hadoop. Supports Map/Reduce, Cascading, Apache Hive and Apache Pig.",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/elasticsearch/elasticsearch-hadoop"
      }
    ]
  },
  {
    "name": "ElephantDB",
    "description": "Distributed database specialized in exporting data from Hadoop",
    "abstract": "Distributed database specialized in exporting data from Hadoop",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "ElephantDB",
        "url": "https://github.com/nathanmarz/elephantdb"
      }
    ]
  },
  {
    "name": "Enigma.io",
    "description": "Freemium robust web application for exploring, filtering, analyzing, searching and exporting massive datasets scraped from across the Web",
    "abstract": "Freemium robust web application for exploring, filtering, analyzing, searching and exporting massive datasets scraped from across the Web",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://enigma.io"
      }
    ]
  },
  {
    "name": "Envisionjs",
    "description": "dynamic HTML5 visualization.",
    "abstract": "dynamic HTML5 visualization",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/HumbleSoftware/envisionjs"
      }
    ]
  },
  {
    "name": "etcML",
    "description": "text classification with machine learning",
    "abstract": "text classification with machine learning",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "",
        "url": "http://www.etcml.com/"
      }
    ]
  },
  {
    "name": "Etsy Conjecture",
    "description": "Conjecture is a framework for building machine learning models in Hadoop using the Scalding DSL. The goal of this project is to enable the development of statistical models as viable components in a wide range of product settings. Applications include classification and categorization, recommender systems, ranking, filtering, and regression (predicting real-valued numbers). Conjecture has been designed with a primary emphasis on flexibility and can handle a wide variety of inputs. Integration with Hadoop and scalding enable seamless handling of extremely large data volumes, and integration with established ETL processes. Predicted labels can either be consumed directly by the web stack using the dataset loader, or models can be deployed and consumed by live web code. Currently, binary classification (assigning one of two possible labels to input data points) is the most mature component of the Conjecture package.",
    "abstract": "scalable Machine Learning in Scalding",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/etsy/Conjecture"
      }
    ]
  },
  {
    "name": "Etsy StatsD",
    "description": "simple daemon for easy stats aggregation",
    "abstract": "simple daemon for easy stats aggregation",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/etsy/statsd/"
      }
    ]
  },
  {
    "name": "Eventhub",
    "description": "open source event analytics platform.",
    "abstract": "open source event analytics platform",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Codecademy/EventHub"
      }
    ]
  },
  {
    "name": "EventStore",
    "description": "An open-source, functional database with support for Complex Event Processing. It provides a persistence engine for applications using event-sourcing, or for storing time-series data. Event Store is written in C#, C++ for the server which runs on Mono or the .NET CLR, on Linux or Windows. Applications using Event Store can be written in JavaScript.",
    "abstract": "distributed time series database",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "EventStore",
        "url": "http://geteventstore.com"
      },
      {
        "text": "Website",
        "url": "http://geteventstore.com/"
      }
    ]
  },
  {
    "name": "Evrything",
    "description": "Making products smart",
    "abstract": "Making products smart",
    "category": "Internet of Things",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://evrythng.com/"
      }
    ]
  },
  {
    "name": "Facebook Apollo",
    "description": "Facebook’s Paxos-like NoSQL database",
    "abstract": "Facebook’s Paxos-like NoSQL database",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "infoQ post",
        "url": "http://www.infoq.com/news/2014/06/facebook-apollo"
      },
      {
        "text": "Website",
        "url": "http://www.infoq.com/news/2014/06/facebook-apollo/"
      }
    ]
  },
  {
    "name": "Facebook Autoscale",
    "description": "the load balancer will concentrate workload to a server until it has at least a medium-level workload",
    "abstract": "the load balancer will concentrate workload to a server until it has at least a medium-level workload",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://code.facebook.com/posts/816473015039157/making-facebook-s-software-infrastructure-more-energy-efficient-with-autoscale/"
      }
    ]
  },
  {
    "name": "Facebook Corona",
    "description": "“The next version of Map-Reduce\" from Facebook, based in own fork of Hadoop. The current Hadoop implementation of the MapReduce technique uses a single job tracker, which causes scaling issues for very large data sets. The Apache Hadoop developers have been creating their own next-generation MapReduce, called YARN, which Facebook engineers looked at but discounted because of the highly-customised nature of the company's deployment of Hadoop and HDFS.\nCorona, like YARN, spawns multiple job trackers (one for each job, in Corona's case). ",
    "abstract": "Hadoop enhancement which removes single point of failure",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.facebook.com/notes/facebook-engineering/under-the-hood-scheduling-mapreduce-jobs-more-efficiently-with-corona/10151142560538920"
      }
    ]
  },
  {
    "name": "Facebook Haystack",
    "description": "object storage system",
    "abstract": "object storage system",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Facebook Haystack",
        "url": "https://www.facebook.com/note.php?note_id=76191543919"
      }
    ]
  },
  {
    "name": "Facebook HydraBase",
    "description": "Evolution of HBase made by Facebook",
    "abstract": "evolution of HBase made by Facebook",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Blog Post on Facebook engineer",
        "url": "https://code.facebook.com/posts/321111638043166/hydrabase-the-evolution-of-hbase-facebook/"
      }
    ]
  },
  {
    "name": "Facebook Iris",
    "description": "a totally ordered queue of messaging updates with separate pointers into the queue indicating the last update sent to your Messenger app and the traditional storage tier",
    "abstract": "a totally ordered queue of messaging updates with separate pointers into the queue indicating the last update sent to your Messenger app and the traditional storage tier",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://code.facebook.com/posts/820258981365363/building-mobile-first-infrastructure-for-messenger/"
      }
    ]
  },
  {
    "name": "Facebook McDipper",
    "description": "key/value cache for flash storage",
    "abstract": "key/value cache for flash storage",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Facebook McDipper",
        "url": "https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920"
      }
    ]
  },
  {
    "name": "Facebook Mcrouter",
    "description": "a memcached protocol router for scaling memcached deployments",
    "abstract": "a memcached protocol router for scaling memcached deployments",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/facebook/mcrouter"
      },
      {
        "text": "Facebook Note",
        "url": "https://code.facebook.com/posts/296442737213493/introducing-mcrouter-a-memcached-protocol-router-for-scaling-memcached-deployments/"
      }
    ]
  },
  {
    "name": "Facebook Memcached",
    "description": "fork of Memcache",
    "abstract": "fork of Memcache",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Facebook Memcached",
        "url": "https://www.facebook.com/notes/facebook-engineering/scaling-memcache-at-facebook/10151411410803920"
      }
    ]
  },
  {
    "name": "Facebook Peregrine",
    "description": "Map Reduce framework",
    "abstract": "Map Reduce framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Facebook Peregrine",
        "url": "http://peregrine_mapreduce.bitbucket.org/"
      }
    ]
  },
  {
    "name": "Facebook PrestoDB",
    "description": "Facebook has open sourced Presto, a SQL engine it says is on average 10 times faster than Hive for running queries across large data sets stored in Hadoop and elsewhere.",
    "abstract": "distributed SQL query engine",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Facebook PrestoDB",
        "url": "http://prestodb.io/"
      }
    ]
  },
  {
    "name": "Facebook Prism",
    "description": "multi datacenters replication system",
    "abstract": "multi datacenters replication system",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.wired.com/2012/08/facebook-prism/"
      }
    ]
  },
  {
    "name": "Facebook Scribe",
    "description": "Log agregator in real-time. It’s a Apache Thrift Service.",
    "abstract": "streamed log data aggregator",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Facebook Scribe",
        "url": "https://github.com/facebook/scribe"
      }
    ]
  },
  {
    "name": "Facebook Scuba",
    "description": "distributed in-memory datastore",
    "abstract": "distributed in-memory datastore",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.facebook.com/notes/facebook-engineering/under-the-hood-data-diving-with-scuba/10150599692628920"
      }
    ]
  },
  {
    "name": "Facebook TAO",
    "description": "TAO is the distributed data store that is widely used at facebook to store and serve the social graph. The entire architecture is highly read optimized, supports a graph data model and works across multiple geographical regions.",
    "abstract": "TAO is the distributed data store that is widely used at facebook to store and serve the social graph",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Post about TAO",
        "url": "https://www.facebook.com/notes/facebook-engineering/tao-the-power-of-the-graph/10151525983993920"
      }
    ]
  },
  {
    "name": "Facebook Unicorn",
    "description": "social graph search platform",
    "abstract": "social graph search platform",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.facebook.com/publications/219621248185635/"
      }
    ]
  },
  {
    "name": "FairCom c-treeACE",
    "description": "a cross-platform database engine",
    "abstract": "a cross-platform database engine",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.faircom.com/ace/ace_t.php"
      }
    ]
  },
  {
    "name": "Faunus",
    "description": "Hadoop-based graph analytics engine for analyzing graphs represented across a multi-machine compute cluster",
    "abstract": "Hadoop-based graph analytics engine for analyzing graphs represented across a multi-machine compute cluster",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://thinkaurelius.github.io/faunus/"
      }
    ]
  },
  {
    "name": "Fig",
    "description": "fast, isolated development environments using Docker",
    "abstract": "fast, isolated development environments using Docker",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.fig.sh/"
      }
    ]
  },
  {
    "name": "Fluentd",
    "description": "tool to collect events and logs",
    "abstract": "tool to collect events and logs",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Fluentd",
        "url": "http://fluentd.org/"
      }
    ]
  },
  {
    "name": "FnordMetric ChartSQL",
    "description": "allows you to write SQL queries that return charts instead of tables.",
    "abstract": "allows you to write SQL queries that return charts instead of tables. The charts are rendered as SVG vector graphics.",
    "category": "Data Visualization",
    "tags": [
      "sql",
      "timeseries",
      "svg"
    ],
    "links": [
      {
        "text": "FnordMetric ChartSQL",
        "url": "http://fnordmetric.io/chartsql/"
      }
    ]
  },
  {
    "name": "FoundationDB",
    "description": "distributed database, inspired by F1, aquired Akiban server",
    "abstract": "distributed database, inspired by F1",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "FoundationDB",
        "url": "https://foundationdb.com/"
      },
      {
        "text": "Akiban Server",
        "content": "http://www.akiban.com"
      }
    ]
  },
  {
    "name": "Freeboard",
    "description": "open source real-time dashboard builder for IOT and other web mashups.",
    "abstract": "open source real-time dashboard builder for IOT and other web mashups",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Freeboard/freeboard"
      }
    ]
  },
  {
    "name": "Ganglia Monitoring System",
    "description": "scalable distributed monitoring system for high-performance computing systems such as clusters and Grids",
    "abstract": "scalable distributed monitoring system for high-performance computing systems such as clusters and Grids",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://ganglia.sourceforge.net/"
      }
    ]
  },
  {
    "name": "Gearman",
    "description": "Job Server",
    "abstract": "Job Server",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://gearman.org"
      }
    ]
  },
  {
    "name": "Genie",
    "description": "Genie provides REST-ful APIs to run Hadoop, Hive and Pig jobs, and to manage multiple Hadoop resources and perform job submissions across them.",
    "abstract": "Genie provides REST-ful APIs to run Hadoop, Hive and Pig jobs, and to manage multiple Hadoop resources and perform job submissions across them.",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/genie"
      }
    ]
  },
  {
    "name": "Geotrellis",
    "description": "geographic data processing engine for high performance applications",
    "abstract": "geographic data processing engine for high performance applications",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://geotrellis.io/"
      },
      {
        "text": "Website",
        "url": "http://spark-summit.org/2014/talk/geotrellis-adding-geospatial-capabilities-to-spark"
      }
    ]
  },
  {
    "name": "Gephi",
    "description": "An award-winning open-source platform for visualizing and manipulating large graphs and network connections. It's like Photoshop, but for graphs. Available for Windows and Mac OS X.",
    "abstract": "An award-winning open-source platform for visualizing and manipulating large graphs and network connections",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/gephi/gephi"
      }
    ]
  },
  {
    "name": "GIS Tools for Hadoop",
    "description": "Big Data Spatial Analytics for the Hadoop Framework",
    "abstract": "Big Data Spatial Analytics for the Hadoop Framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://esri.github.io/gis-tools-for-hadoop/"
      }
    ]
  },
  {
    "name": "Google BigQuery",
    "description": "framework for interactive analysis, implementation of Dremel",
    "abstract": "framework for interactive analysis, implementation of Dremel",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Google BigQuery",
        "url": "http://research.google.com/pubs/pub36632.html"
      }
    ]
  },
  {
    "name": "Google BigTable",
    "description": "column-oriented distributed datastore",
    "abstract": "column-oriented distributed datastore",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Google BigTable",
        "url": "http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//archive/bigtable-osdi06.pdf"
      }
    ]
  },
  {
    "name": "Google Borg",
    "description": "job scheduling and monitoring system",
    "abstract": "job scheduling and monitoring system",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Wired article",
        "url": "http://www.wired.com/wiredenterprise/2013/03/google-borg-twitter-mesos/all/"
      }
    ]
  },
  {
    "name": "Google Caffeine",
    "description": "continuous indexing system",
    "abstract": "continuous indexing system",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Google blog post",
        "url": "http://googleblog.blogspot.it/2010/06/our-new-search-index-caffeine.html"
      }
    ]
  },
  {
    "name": "Google Cayley",
    "description": "open-source graph database.",
    "abstract": "open-source graph database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/google/cayley"
      }
    ]
  },
  {
    "name": "Google Charts",
    "description": "simple charting API.",
    "abstract": "simple charting API",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://developers.google.com/chart/"
      }
    ]
  },
  {
    "name": "Google Chubby",
    "description": "a lock service for loosely-coupled distributed systems",
    "abstract": "a lock service for loosely-coupled distributed systems",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Paper",
        "url": "http://research.google.com/archive/chubby.html"
      }
    ]
  },
  {
    "name": "Google Cloud Datastore",
    "description": "is a fully managed, schemaless database for storing non-relational data built on top of Google’s BigTable infrastructure",
    "abstract": "is a fully managed, schemaless database for storing non-relational data over BigTable",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Google Cloud Datastore site",
        "url": "https://developers.google.com/datastore/"
      },
      {
        "text": "Google App Engine Datastore",
        "url": "https://developers.google.com/appengine/docs/python/datastore/"
      },
      {
        "text": "Matering Datastore",
        "url": "https://developers.google.com/appengine/articles/datastore/overview"
      }
    ]
  },
  {
    "name": "Google Cloud SQL",
    "description": "MySQL databases in Google's cloud",
    "abstract": "MySQL databases in Google's cloud",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Google Cloud SQL",
        "url": "https://developers.google.com/cloud-sql/"
      }
    ]
  },
  {
    "name": "Google Colossus",
    "description": "distributed filesystem (GFS2)",
    "abstract": "distributed filesystem (GFS2)",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://google.com/"
      }
    ]
  },
  {
    "name": "Google Container Engine",
    "description": "Run Docker containers on Google Cloud Platform, powered by Kubernetes",
    "abstract": "Run Docker containers on Google Cloud Platform, powered by Kubernetes",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://cloud.google.com/container-engine/"
      }
    ]
  },
  {
    "name": "Google Dataflow",
    "description": "create data pipelines to help themæingest, transform and analyze data",
    "abstract": "create data pipelines to help themæingest, transform and analyze data",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://googledevelopers.blogspot.it/2014/06/cloud-platform-at-google-io-new-big.html"
      }
    ]
  },
  {
    "name": "Google Dremel",
    "description": "framework for interactive analysis, implementation of Dremel",
    "abstract": "framework for interactive analysis, implementation of Dremel",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Dremel Paper",
        "url": "http://research.google.com/pubs/pub36632.html"
      }
    ]
  },
  {
    "name": "Google F1",
    "description": "distributed SQL database built on Spanner",
    "abstract": "distributed SQL database built on Spanner",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/pubs/pub41344.html"
      }
    ]
  },
  {
    "name": "Google Firebase",
    "description": "a powerful API to store and sync data in realtime",
    "abstract": "a powerful API to store and sync data in realtime",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.firebase.com/"
      }
    ]
  },
  {
    "name": "Google GFS",
    "description": "distributed filesystem",
    "abstract": "distributed filesystem",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://google.com/"
      }
    ]
  },
  {
    "name": "Google MapReduce",
    "description": "map reduce framework",
    "abstract": "map reduce framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/archive/mapreduce.html"
      }
    ]
  },
  {
    "name": "Google Megastore",
    "description": "scalable, highly available storage",
    "abstract": "scalable, highly available storage",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/pubs/pub36971.html"
      }
    ]
  },
  {
    "name": "Google Mesa",
    "description": "highly scalable analytic data warehousing system",
    "abstract": "highly scalable analytic data warehousing system",
    "category": "Data Warehouse",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/42851.pdf"
      }
    ]
  },
  {
    "name": "Google MillWheel",
    "description": "fault tolerant stream processing framework",
    "abstract": "fault tolerant stream processing framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/pubs/pub41378.html"
      }
    ]
  },
  {
    "name": "Google Omega",
    "description": "job scheduling and monitoring system",
    "abstract": "job scheduling and monitoring system",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Talk",
        "url": "https://www.youtube.com/watch?v=0ZFMlO98Jkc"
      }
    ]
  },
  {
    "name": "Google Percolator",
    "description": "continuous indexing system",
    "abstract": "continuous indexing system",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Paper",
        "url": "http://research.google.com/pubs/pub36726.html"
      }
    ]
  },
  {
    "name": "Google Photon",
    "description": "geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency",
    "abstract": "geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/pubs/pub41318.html"
      }
    ]
  },
  {
    "name": "Google Pregel",
    "description": "graph processing framework",
    "abstract": "graph processing framework",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://kowshik.github.io/JPregel/pregel_paper.pdf"
      }
    ]
  },
  {
    "name": "Google Sibyl",
    "description": "System for Large Scale Machine Learning at Google",
    "abstract": "System for Large Scale Machine Learning at Google",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf"
      },
      {
        "text": "Website",
        "url": "http://www.datanami.com/2014/07/17/inside-sibyl-googles-massively-parallel-machine-learning-platform/"
      },
      {
        "text": "Website",
        "url": "http://www.magicbroom.info/Papers/Ladis10.pdf"
      }
    ]
  },
  {
    "name": "Google Spanner",
    "description": "globally distributed semi-relational database",
    "abstract": "globally distributed semi-relational database",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.google.com/archive/spanner.html"
      }
    ]
  },
  {
    "name": "TeraGoogle",
    "description": "large search index",
    "abstract": "large search index",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "",
        "url": ""
      }
    ]
  },
  {
    "name": "Grafana",
    "description": "open source, feature rich metrics dashboard and graph editor for  Graphite, InfluxDB & OpenTSDB",
    "abstract": "open source, feature rich metrics dashboard and graph editor for  Graphite, InfluxDB & OpenTSDB",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://grafana.org/"
      }
    ]
  },
  {
    "name": "Graphite",
    "description": "scalable Realtime Graphing.",
    "abstract": "scalable Realtime Graphing",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://graphite.wikidot.com/"
      }
    ]
  },
  {
    "name": "GraphLab PowerGraph",
    "description": "a core C++ GraphLab API and a collection of high-performance machine learning and data mining toolkits built on top of the GraphLab API.  In addition, we are actively developing new interfaces to allow users to leverage the GraphLab API from other languages and technologies.",
    "abstract": "a core C++ GraphLab API and a collection of high-performance machine learning and data mining toolkits built on top of the GraphLab API",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Graphlab website",
        "url": "http://graphlab.org/projects/source.html"
      }
    ]
  },
  {
    "name": "GraphX",
    "description": "A Resilient Distributed Graph System on Spark",
    "abstract": "resilient Distributed Graph System on Spark",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "GraphX",
        "url": "https://amplab.cs.berkeley.edu/publication/graphx-grades/"
      }
    ]
  },
  {
    "name": "Gremlin",
    "description": "graph traversal Language.",
    "abstract": "graph traversal Language",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/tinkerpop/gremlin"
      }
    ]
  },
  {
    "name": "GridGain",
    "description": "GridGain is open source project licensed under Apache 2.0. One of the main pieces of this platform is the In-Memory Apache Hadoop Accelerator which aims to accelerate HDFS and Map/Reduce by bringing both, data and computations into memory. This work is done with the GGFS - Hadoop compliant in-memory file system. For I/O intensive jobs GridGain GGFS offers performance close to 100x faster than standard HDFS. Paraphrasing Dmitriy Setrakyan from GridGain Systems talking about GGFS regarding Tachyon: GGFS allows read-through and write-through to/from underlying HDFS or any other Hadoop compliant file system with zero code change. Essentially GGFS entirely removes ETL step from integration.GGFS has ability to pick and choose what folders stay in memory, what folders stay on disc, and what folders get synchronized with underlying (HD)FS either synchronously or asynchronously. GridGain is working on adding native MapReduce component which will provide native complete Hadoop integration without changes in API, like Spark currently forces you to do. Essentially GridGain MR+GGFS will allow to bring Hadoop completely or partially in-memory in Plug-n-Play fashion without any API changes. ",
    "abstract": "GGFS, Hadoop compliant in-memory file system",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "GridGain site",
        "url": "http://www.gridgain.org/"
      }
    ]
  },
  {
    "name": "H-Store",
    "description": "is an experimental main-memory, parallel database management system that is optimized for on-line transaction processing (OLTP) applications. It is a highly distributed, row-store-based relational database that runs on a cluster on shared-nothing, main memory executor nodes.",
    "abstract": "is an experimental main-memory, parallel database management system that is optimized for on-line transaction processing (OLTP) applications",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Brown project website",
        "url": "http://hstore.cs.brown.edu/"
      }
    ]
  },
  {
    "name": "H2O",
    "description": "statistical, machine learning and math runtime for Hadoop",
    "abstract": "statistical, machine learning and math runtime for Hadoop",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "H2O",
        "url": "http://0xdata.github.io/h2o/"
      }
    ]
  },
  {
    "name": "Hadapt",
    "description": "a native implementation of SQL for the Apache Hadoop open-source project",
    "abstract": "a native implementation of SQL for the Apache Hadoop open-source project",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://hadapt.com/"
      }
    ]
  },
  {
    "name": "HadoopDB",
    "description": "hybrid of MapReduce and DBMS",
    "abstract": "hybrid of MapReduce and DBMS",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "HadoopDB",
        "url": "http://db.cs.yale.edu/hadoopdb/hadoopdb.html"
      }
    ]
  },
  {
    "name": "Haeinsa",
    "description": "Haeinsa is linearly scalable multi-row, multi-table transaction library for HBase. Use Haeinsa if you need strong ACID semantics on your HBase cluster. Is based on Google Perlcoator concept.",
    "abstract": "linearly scalable multi-row, multi-table transaction library for HBase based on Percolator",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/VCNC/haeinsa"
      }
    ]
  },
  {
    "name": "HamsterDB",
    "description": "transactional key-value database",
    "abstract": "transactional key-value database",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://hamsterdb.com/"
      }
    ]
  },
  {
    "name": "HandlerSocket",
    "description": "HandlerSocket is a NoSQL plugin for MySQL/MariaDB (the storage engine of MySQL). It works as a daemon inside the mysqld process, accepting TCP connections, and executing requests from clients. HandlerSocket does not support SQL queries. Instead, it supports simple CRUD operations on tables.\nHandlerSocket can be much faster than mysqld/libmysql in some cases because it has lower CPU, disk, and network overhead.",
    "abstract": "NoSQL plugin for MySQL/MariaDB",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.percona.com/doc/percona-server/5.5/performance/handlersocket.html"
      }
    ]
  },
  {
    "name": "Hannibal",
    "description": "Hannibal is tool to help monitor and maintain HBase-Clusters that are configured for manual splitting.",
    "abstract": "Hannibal is tool to help monitor and maintain HBase-Clusters that are configured for manual splitting.",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/sentric/hannibal"
      }
    ]
  },
  {
    "name": "HanoiDB",
    "description": "HanoiDB implements an indexed, key/value storage engine. The primary index is a log-structured merge tree (LSM-BTree) implemented using 'doubling sizes' persistent ordered sets of key/value pairs, similar is some regards to LevelDB. HanoiDB includes a visualizer which when used to watch a living database resembles the 'Towers of Hanoi' puzzle game, which inspired the name of this database.",
    "abstract": "Erlang LSM BTree Storage",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/krestenkrab/hanoidb"
      }
    ]
  },
  {
    "name": "Hazelcast",
    "description": "In-Memory Data Grid",
    "abstract": "In-Memory Data Grid",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://hazelcast.com/products/hazelcast/"
      }
    ]
  },
  {
    "name": "HBase Coprocessor",
    "description": "implementation of Percolator, part of HBase",
    "abstract": "implementation of Percolator, part of HBase",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "HBase Coprocessor",
        "url": "https://blogs.apache.org/hbase/entry/coprocessor_introduction"
      }
    ]
  },
  {
    "name": "HDSF-DU",
    "description": "HDFS-DU is an interactive visualization of the Hadoop distributed file system. ",
    "abstract": "HDFS-DU is an interactive visualization of the Hadoop distributed file system. ",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/twitter/hdfs-du"
      }
    ]
  },
  {
    "name": "Heka",
    "description": "open source stream processing software system.",
    "abstract": "open source stream processing software system",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/mozilla-services/heka"
      }
    ]
  },
  {
    "name": "Highcharts",
    "description": "simple and flexible charting API.",
    "abstract": "simple and flexible charting API",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.highcharts.com/"
      }
    ]
  },
  {
    "name": "HIHO",
    "description": "This project is a framework for connecting disparate data sources with the Apache Hadoop system, making them interoperable. HIHO connects Hadoop with multiple RDBMS and file systems, so that data can be loaded to Hadoop and unloaded from Hadoop",
    "abstract": "framework for connecting disparate data sources with Hadoop",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/sonalgoyal/hiho"
      }
    ]
  },
  {
    "name": "hIndex",
    "description": "Secondary Index for HBase",
    "abstract": "Secondary Index for HBase",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Huawei-Hadoop/hindex"
      }
    ]
  },
  {
    "name": "HIPI Library",
    "description": "HIPI is a library for Hadoop's MapReduce framework that provides an API for performing image processing tasks in a distributed computing environment.",
    "abstract": "API for performing image processing tasks on Hadoop's MapReduce",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://hipi.cs.virginia.edu/"
      }
    ]
  },
  {
    "name": "Hive-benchmarks",
    "description": "some benchmarking queries for Apache Hive",
    "abstract": "some benchmarking queries for Apache Hive",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/yhuai/hive-benchmarks"
      }
    ]
  },
  {
    "name": "Hive-testbench",
    "description": "Testbench for experimenting with Apache Hive at any data scale.",
    "abstract": "Testbench for experimenting with Apache Hive at any data scale.",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/cartershanklin/hive-testbench"
      }
    ]
  },
  {
    "name": "HornetQ",
    "description": "open source project to build a multi-protocol, embeddable, very high performance, clustered, asynchronous messaging system",
    "abstract": "open source project to build a multi-protocol, embeddable, very high performance, clustered, asynchronous messaging system",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.jboss.org/hornetq"
      }
    ]
  },
  {
    "name": "Hortonworks HOYA",
    "description": "HOYA is defined as “running HBase On YARN”. The Hoya tool is a Java tool, and is currently CLI driven. It takes in a cluster specification – in terms of the number of regionservers, the location of HBASE_HOME, the ZooKeeper quorum hosts, the configuration that the new HBase cluster instance should use and so on.",
    "abstract": "application that can deploy HBase cluster on YARN",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Hortonworks Blog",
        "url": "http://hortonworks.com/blog/introducing-hoya-hbase-on-yarn/"
      }
    ]
  },
  {
    "name": "HParser",
    "description": "data parsing transformation environment optimized for Hadoop",
    "abstract": "data parsing transformation environment optimized for Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.informatica.com/us/products/big-data/hparser/"
      }
    ]
  },
  {
    "name": "Hunk",
    "description": "Splunk analytics for Hadoop",
    "abstract": "Splunk analytics for Hadoop",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Hunk",
        "url": "http://www.splunk.com/download/hunk"
      }
    ]
  },
  {
    "name": "HyperDex",
    "description": "next generation key-value store",
    "abstract": "next generation key-value store",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://hyperdex.org/"
      }
    ]
  },
  {
    "name": "HyperGraphDB",
    "description": "general purpose, open-source data storage mechanism based on a powerful knowledge management formalism known as directed hypergraphs",
    "abstract": "general purpose, open-source data storage mechanism based on a powerful knowledge management formalism known as directed hypergraphs",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.hypergraphdb.org/"
      }
    ]
  },
  {
    "name": "Hypertable",
    "description": "Database system inspired by publications on the design of Google's BigTable. The project is based on experience of engineers who were solving large-scale data-intensive tasks for many years. Hypertable runs on top of a distributed file system such as the Apache Hadoop DFS, GlusterFS, or the Kosmos File System (KFS). It is written almost entirely in C++. Sposored by Baidu the Chinese search engine.",
    "abstract": "column-oriented distribuited datastore, inspired by BigTable",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "HyperTable",
        "url": "http://hypertable.org/"
      }
    ]
  },
  {
    "name": "IBM BigInsights",
    "description": "data processing, warehousing and analytics",
    "abstract": "data processing, warehousing and analytics",
    "category": "Data Warehouse",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ibm.com/software/data/infosphere/biginsights/"
      }
    ]
  },
  {
    "name": "IBM dashDB",
    "description": "Data Warehousing and Analysis Needs, all in the Cloud",
    "abstract": "Data Warehousing and Analysis Needs, all in the Cloud",
    "category": "Data Warehouse",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://cloudant.com/dashdb/"
      }
    ]
  },
  {
    "name": "IBM DB2",
    "description": "object-relational database management system",
    "abstract": "object-relational database management system",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ibm.com/software/data/db2/"
      }
    ]
  },
  {
    "name": "IBM Netezza",
    "description": "high-performance data warehouse appliances",
    "abstract": "high-performance data warehouse appliances",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www-01.ibm.com/software/data/netezza/"
      }
    ]
  },
  {
    "name": "IBM Streams",
    "description": "advanced analytic platform that allows user-developed applications to quickly ingest, analyze and correlate information as it arrives from thousands of real-time sources",
    "abstract": "advanced analytic platform that allows user-developed applications to quickly ingest, analyze and correlate information as it arrives from thousands of real-time sources",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ibm.com/software/products/en/infosphere-streams"
      }
    ]
  },
  {
    "name": "IBM Watson",
    "description": "cognitive computing system",
    "abstract": "cognitive computing system",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ibm.com/smarterplanet/us/en/ibmwatson/"
      }
    ]
  },
  {
    "name": "InfiniDB",
    "description": "is accessed through a MySQL interface and use massive parallel processing to parallelize queries",
    "abstract": "is accessed through a MySQL interface and use massive parallel processing to parallelize queries",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://infinidb.co/"
      }
    ]
  },
  {
    "name": "InfiniSQL",
    "description": "infinity scalable RDBMS",
    "abstract": "infinity scalable RDBMS",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "InfiniSQL",
        "url": "http://www.infinisql.org/"
      }
    ]
  },
  {
    "name": "InfiniteGraph",
    "description": "distributed graph database",
    "abstract": "distributed graph database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.objectivity.com/infinitegraph"
      }
    ]
  },
  {
    "name": "InfluxDB",
    "description": "InfluxDB is an open source distributed time series database with no external dependencies. It's useful for recording metrics, events, and performing analytics.\nIt has a built-in HTTP API so you don't have to write any server side code to get up and running. InfluxDB is designed to be scalable, simple to install and manage, and fast to get data in and out. It aims to answer queries in real-time. That means every data point is indexed as it comes in and is immediately available in queries that should return in \n",
    "abstract": "distributed time series database",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://influxdb.com/"
      }
    ]
  },
  {
    "name": "Infovore",
    "description": "RDF-centric Map/Reduce framework",
    "abstract": "RDF-centric Map/Reduce framework",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/paulhoule/infovore"
      }
    ]
  },
  {
    "name": "Intel GraphBuilder",
    "description": "library which provides tools to construct large-scale graphs on top of Apache Hadoop",
    "abstract": "tools to construct large-scale graphs on top of Hadoop",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://01.org/graphbuilder/"
      }
    ]
  },
  {
    "name": "Intel HiBench",
    "description": "HiBench is a Hadoop benchmark suite.",
    "abstract": "a Hadoop benchmark suite",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/intel-hadoop/HiBench"
      }
    ]
  },
  {
    "name": "IPython",
    "description": "provides a rich architecture for interactive computing",
    "abstract": "provides a rich architecture for interactive computing",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://ipython.org/"
      }
    ]
  },
  {
    "name": "IronMQ",
    "description": "easy-to-use highly available message queuing service",
    "abstract": "easy-to-use highly available message queuing service",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.iron.io/mq"
      }
    ]
  },
  {
    "name": "SF1R Search Engine",
    "description": "distributed high performance massive data engine for enterprise/vertical search",
    "abstract": "distributed search engine written in c++",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "SF1R",
        "url": "http://github.com/izenecloud/sf1r-lite"
      }
    ]
  },
  {
    "name": "JAQL",
    "description": "JAQL is a functional, declarative programming language designed especially for working with large volumes of structured, semi-structured and unstructured data. As its name implies, a primary use of JAQL is to handle data stored as JSON documents, but JAQL can work on various types of data. For example, it can support XML, comma-separated values (CSV) data and flat files. A \"SQL within JAQL\" capability lets programmers work with structured SQL data while employing a JSON data model that's less restrictive than its Structured Query Language counterparts.",
    "abstract": "declarative programming language for working with structured, semi-structured and unstructured data",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "JAQL in Google Code",
        "url": "https://code.google.com/p/jaql/"
      },
      {
        "text": "What is Jaql? by IBM",
        "url": "http://www-01.ibm.com/software/data/infosphere/hadoop/jaql/"
      }
    ]
  },
  {
    "name": "Jaspersoft",
    "description": "powerful business intelligence suite.",
    "abstract": "powerful business intelligence suite",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.jaspersoft.com/"
      }
    ]
  },
  {
    "name": "Jedox Palo",
    "description": "Palo Suite combines all core applications — OLAP Server, Palo Web, Palo ETL Server and Palo for Excel — into one comprehensive and customisable Business Intelligence platform. The platform is completely based on Open Source products representing a high-end Business Intelligence solution which is available entirely free of any license fees.",
    "abstract": "customisable Business Intelligence platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.jedox.com/"
      }
    ]
  },
  {
    "name": "JethroData",
    "description": "index-based SQL engine for Hadoop",
    "abstract": "index-based SQL engine for Hadoop",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://jethrodata.com/product-2/product/"
      }
    ]
  },
  {
    "name": "jumboDB",
    "description": "document oriented datastore over Hadoop",
    "abstract": "document oriented datastore over Hadoop",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "jumboDB",
        "url": "http://comsysto.github.io/jumbodb/"
      }
    ]
  },
  {
    "name": "Jumbune",
    "description": "Jumbune is an open-source product built for analyzing Hadoop cluster and MapReduce jobs.",
    "abstract": "Jumbune is an open-source product built for analyzing Hadoop cluster and MapReduce jobs.",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.jumbune.org/"
      },
      {
        "text": "Github",
        "url": "https://github.com/impetus-opensource/jumbune"
      }
    ]
  },
  {
    "name": "KAI",
    "description": "a distributed key-value datastore",
    "abstract": "a distributed key-value datastore",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://sourceforge.net/projects/kai/"
      }
    ]
  },
  {
    "name": "Kairosdb",
    "description": "similar to OpenTSDB but allows for Cassandra",
    "abstract": "similar to OpenTSDB but allows for Cassandra",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://code.google.com/p/kairosdb/"
      }
    ]
  },
  {
    "name": "Kestrel",
    "description": "distributed message queue system",
    "abstract": "distributed message queue system",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Kestrel",
        "url": "http://robey.github.io/kestrel/"
      }
    ]
  },
  {
    "name": "Keylines",
    "description": "toolkit for visualizing the networks in your data",
    "abstract": "toolkit for visualizing the networks in your data",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://keylines.com/"
      }
    ]
  },
  {
    "name": "Kibana",
    "description": "visualize logs and time-stamped data",
    "abstract": "visualize logs and time-stamped data",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.elasticsearch.org/overview/kibana/"
      }
    ]
  },
  {
    "name": "Kite",
    "description": "is a set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem.",
    "abstract": "is a set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://kitesdk.org/docs/current/"
      }
    ]
  },
  {
    "name": "Kryo",
    "description": "Java serialization and cloning: fast, efficient, automatic",
    "abstract": "Java serialization and cloning: fast, efficient, automatic",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/EsotericSoftware/kryo"
      }
    ]
  },
  {
    "name": "Kubernetes",
    "description": "open source implementation of container cluster management",
    "abstract": "open source implementation of container cluster management",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/GoogleCloudPlatform/kubernetes"
      }
    ]
  },
  {
    "name": "Kylin",
    "description": "open source Distributed Analytics Engine from eBay",
    "abstract": "open source Distributed Analytics Engine from eBay",
    "category": null,
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.kylin.io/"
      }
    ]
  },
  {
    "name": "Lavastorm Analytics",
    "description": "used for audit analytics, revenue assurance, fraud management, and customer experience management",
    "abstract": "used for audit analytics, revenue assurance, fraud management, and customer experience management",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.lavastorm.com/"
      }
    ]
  },
  {
    "name": "LevelDB",
    "description": "a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.",
    "abstract": "a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Google code website",
        "url": "https://code.google.com/p/leveldb/"
      }
    ]
  },
  {
    "name": "Lily HBase Indexer",
    "description": "quickly and easily search for any content stored in HBase",
    "abstract": "quickly and easily search for any content stored in HBase",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://ngdata.github.io/hbase-indexer/"
      }
    ]
  },
  {
    "name": "Linkedin Azkaban",
    "description": "Hadoop workflow management. A batch job scheduler can be seen as a combination of the cron and make Unix utilities combined with a friendly UI.",
    "abstract": "batch workflow job scheduler",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn Azkaban",
        "url": "http://azkaban.github.io/azkaban2/"
      }
    ]
  },
  {
    "name": "LinkedIn Bobo",
    "description": "is a Faceted Search implementation written purely in Java, an extension to Apache Lucene.",
    "abstract": "is a Faceted Search implementation written purely in Java, an extension to Apache Lucene",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Github Page",
        "url": "http://senseidb.github.io/bobo/"
      }
    ]
  },
  {
    "name": "LinkedIn Camus",
    "description": "Kafka to HDFS pipeline. It is a mapreduce job that does distributed data loads out of Kafka",
    "abstract": "Kafka to HDFS pipeline. It is a mapreduce job that does distributed data loads out of Kafka",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/linkedin/camus"
      }
    ]
  },
  {
    "name": "LinkedIn Cleo",
    "description": "Cleo is a flexible software library for enabling rapid development of partial, out-of-order and real-time typeahead search. It is suitable for data sets of varying sizes and types. Cleo has been used extensively to power LinkedIn typeahead search covering professional network connections, companies, groups, questions, skills and other site features.",
    "abstract": "is a flexible software library for enabling rapid development of partial, out-of-order and real-time typeahead search",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/linkedin/cleo"
      }
    ]
  },
  {
    "name": "LinkedIn Cubert",
    "description": "a fast and efficient batch computation engine for complex analysis and reporting of massive datasets on Hadoop",
    "abstract": "a fast and efficient batch computation engine for complex analysis and reporting of massive datasets on Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/linkedin/Cubert"
      }
    ]
  },
  {
    "name": "LinkedIn Databus",
    "description": "stream of change capture events for a database",
    "abstract": "stream of change capture events for a database",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn Databus",
        "url": "http://data.linkedin.com/projects/databus"
      }
    ]
  },
  {
    "name": "LinkedIn Espresso",
    "description": "horizontally scalable document-oriented NoSQL data store",
    "abstract": "horizontally scalable document-oriented NoSQL data store",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn Espresso",
        "url": "http://data.linkedin.com/projects/espresso"
      }
    ]
  },
  {
    "name": "LinkedIn Galene",
    "description": "search architecture at LinkedIn",
    "abstract": "search architecture at LinkedIn",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Blog post on LinkedIn engineer",
        "url": "http://engineering.linkedin.com/search/did-you-mean-galene"
      }
    ]
  },
  {
    "name": "LinkedIn Gobblin",
    "description": "a framework for Solving Big Data Ingestion Problem",
    "abstract": "a framework for Solving Big Data Ingestion Problem",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.linkedin.com/data-ingestion/gobblin-big-data-ease"
      }
    ]
  },
  {
    "name": "LinkedIn GoSpeed",
    "description": "provides RUM data processing, visualization, monitoring, and analyses data daily, hourly, or on a near real-time basis",
    "abstract": "provides RUM data processing, visualization, monitoring, and analyses data daily, hourly, or on a near real-time basis",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.linkedin.com/performance/monitor-and-improve-web-performance-using-rum-data-visualization"
      }
    ]
  },
  {
    "name": "LinkedIn Kamikaze",
    "description": "utility package for compressing sorted integer arrays",
    "abstract": "utility package for compressing sorted integer arrays",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn Kamikaze",
        "url": "https://github.com/linkedin/kamikaze"
      }
    ]
  },
  {
    "name": "LinkedIn Krati",
    "description": "is a simple persistent data store with very low latency and high throughput. It is designed for easy integration with read-write-intensive applications with little effort in tuning configuration, performance and JVM garbage collection.",
    "abstract": "is a simple persistent data store with very low latency and high throughput",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/linkedin-sna/sna-page/tree/master/krati"
      }
    ]
  },
  {
    "name": "Linkedin Lumos",
    "description": "bridge from OLTP to OLAP for use it on Hadoop",
    "abstract": "bridge from OLTP to OLAP for use it on Hadoop",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.slideshare.net/Hadoop_Summit/th-220p230-cramachandranv1"
      }
    ]
  },
  {
    "name": "LinkedIn ml-ease",
    "description": "ADMM based large scale logistic regression",
    "abstract": "ADMM based large scale logistic regression",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/linkedin/ml-ease"
      }
    ]
  },
  {
    "name": "Linkedin Norbert",
    "description": "Norbert is a library that provides easy cluster management and workload distribution. With Norbert, you can quickly distribute a simple client/server architecture to create a highly scalable architecture capable of handling heavy traffic. Implemented in Scala, Norbert wraps ZooKeeper, Netty and uses Protocol Buffers for transport to make it easy to build a cluster aware application. A Java API is provided and pluggable load balancing strategies are supported with round robin and consistent hash strategies provided out of the box.",
    "abstract": "cluster manager",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Linedin Project",
        "url": "http://data.linkedin.com/opensource/norbert"
      },
      {
        "text": "GitHub source code",
        "url": "https://github.com/rhavyn/norbert"
      }
    ]
  },
  {
    "name": "LinkedIn Pinot",
    "description": "a distributed system that supports columnar indexes with the ability to add new types of indexes",
    "abstract": "a distributed system that supports columnar indexes with the ability to add new types of indexes",
    "category": "Data Analysis",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot"
      }
    ]
  },
  {
    "name": "Linkedin Voldemort",
    "description": "Distributed data store that is designed as a key-value store used by LinkedIn for high-scalability storage.",
    "abstract": "distributed key/value storage system",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn Voldemort",
        "url": "http://www.project-voldemort.com/voldemort/"
      }
    ]
  },
  {
    "name": "LinkedIn White Elephant",
    "description": "log aggregator and dashboard",
    "abstract": "log aggregator and dashboard",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "LinkedIn White Elephant",
        "url": "https://github.com/linkedin/white-elephant"
      }
    ]
  },
  {
    "name": "LinkedIn Zoie",
    "description": "Zoie is a realtime search/indexing system written in Java.",
    "abstract": "is a realtime search/indexing system written in Java",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/senseidb/zoie"
      }
    ]
  },
  {
    "name": "Lipstick",
    "description": "Pig workflow visualization tool",
    "abstract": "Pig workflow visualization tool",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/Lipstick"
      }
    ]
  },
  {
    "name": "LMDB",
    "description": "ultra-fast, ultra-compact key-value embedded data store developed by Symas",
    "abstract": "ultra-fast, ultra-compact key-value embedded data store developed by Symas",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Symas website",
        "url": "http://symas.com/mdb/"
      }
    ]
  },
  {
    "name": "Logstash",
    "description": "a tool for managing events and logs.",
    "abstract": "a tool for managing events and logs",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://logstash.net"
      }
    ]
  },
  {
    "name": "Lustre file system",
    "description": "The Lustre filesystem is a high-performance distributed filesystem \nintended for larger network and high-availability environments. \nTraditionally, Lustre is configured to manage remote data storage \ndisk devices within a Storage Area Network (SAN), which is two or \nmore remotely attached disk devices communicating via a Small Computer \nSystem Interface (SCSI) protocol. This includes Fibre Channel, Fibre \nChannel over Ethernet (FCoE), Serial Attached SCSI (SAS) and even iSCSI. ",
    "abstract": "high-performance distributed filesystem",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "wiki.lustre.org/",
        "url": "http://wiki.lustre.org/"
      },
      {
        "text": "Hadoop with Lustre",
        "url": "http://wiki.lustre.org/index.php/Running_Hadoop_with_Lustre"
      },
      {
        "text": "Intel HPC Hadoop",
        "url": "http://hadoop.intel.com/products/distribution"
      }
    ]
  },
  {
    "name": "MADlib",
    "description": "The MADlib project leverages the data-processing capabilities of an RDBMS to analyze data. The aim of this project is the integration of statistical data analysis into databases. The MADlib project is self-described as the Big Data Machine Learning in SQL for Data Scientists. The MADlib software project began the following year as a collaboration between researchers at UC Berkeley and engineers and data scientists at EMC/Greenplum (now Pivotal)",
    "abstract": "data-processing library of an RDBMS to analyze data",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "MADlib Community",
        "url": "http://madlib.net/community/"
      }
    ]
  },
  {
    "name": "Map-D",
    "description": "GPU in-memory database, big data analysis and visualization platform",
    "abstract": "GPU in-memory database, big data analysis and visualization platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.map-d.com/"
      }
    ]
  },
  {
    "name": "MapGraph",
    "description": "Massively Parallel Graph processing on GPUs",
    "abstract": "Massively Parallel Graph processing on GPUs",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://mapgraph.io/"
      }
    ]
  },
  {
    "name": "MapR-DB",
    "description": "fast, scalable, and enterprise-ready in-Hadoop database architected to manage big data",
    "abstract": "fast, scalable, and enterprise-ready in-Hadoop database architected to manage big data",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://content.dataversity.net/rs/wilshireconferences/images/MapR-DB_Product_Preview_for_NoSQL_Now.pdf"
      }
    ]
  },
  {
    "name": "Marathon",
    "description": "Marathon is a Mesos framework for long-running services. Given that you have Mesos running as the kernel for your datacenter, Marathon is the init or upstart daemon.",
    "abstract": "Mesos framework for long-running services",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/mesosphere/marathon"
      }
    ]
  },
  {
    "name": "Marconi",
    "description": "queuing and notification service made by and for OpenStack, but not only for it",
    "abstract": "queuing and notification service made by and for OpenStack, but not only for it",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://wiki.openstack.org/wiki/Marconi"
      }
    ]
  },
  {
    "name": "MariaDB",
    "description": "enhanced, drop-in replacement for MySQL",
    "abstract": "enhanced, drop-in replacement for MySQL",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "MariaDB",
        "url": "https://mariadb.org/"
      }
    ]
  },
  {
    "name": "MariaDB Galera",
    "description": "a synchronous multi-master cluster for MariaDB",
    "abstract": "a synchronous multi-master cluster for MariaDB",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://mariadb.com/kb/en/mariadb/documentation/replication/galera/"
      }
    ]
  },
  {
    "name": "MarkLogic",
    "description": "Schema-agnostic Enterprise NoSQL database technology",
    "abstract": "Schema-agnostic Enterprise NoSQL database technology",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.marklogic.com/"
      }
    ]
  },
  {
    "name": "Matplotlib",
    "description": "plotting with Python.",
    "abstract": "plotting with Python",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/matplotlib/matplotlib"
      }
    ]
  },
  {
    "name": "MemcacheDB",
    "description": "a distributed key-value storage system designed for persistent",
    "abstract": "a distributed key-value storage system designed for persistent",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://memcachedb.org/"
      }
    ]
  },
  {
    "name": "MemSQL",
    "description": "in memory SQL database witho optimized columnar storage on flash",
    "abstract": "in memory SQL database witho optimized columnar storage on flash",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "MemSQL site",
        "url": "http://www.memsql.com/"
      }
    ]
  },
  {
    "name": "Metamarkers Druid",
    "description": "Realtime analytical data store.",
    "abstract": "framework for real-time analysis of large datasets",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Druid",
        "url": "http://druid.io/"
      }
    ]
  },
  {
    "name": "Metanautix Quest",
    "description": "data compute engine",
    "abstract": "data compute engine",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://metanautix.com/product/"
      }
    ]
  },
  {
    "name": "Microsoft",
    "description": "business intelligence software and platform.",
    "abstract": "business intelligence software and platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.microsoft.com/en-us/server-cloud/solutions/business-intelligence/default.aspx"
      }
    ]
  },
  {
    "name": "Microsoft Cosmos",
    "description": "Microsoft's internal BigData analysis platform",
    "abstract": "Microsoft's internal BigData analysis platform",
    "category": "Data Warehouse",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://research.microsoft.com/en-us/events/fs2011/helland_cosmos_big_data_and_big_challenges.pdf"
      }
    ]
  },
  {
    "name": "Microsoft DocumentDB",
    "description": "fully-managed, highly-scalable, NoSQL document database service",
    "abstract": "fully-managed, highly-scalable, NoSQL document database service",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://azure.microsoft.com/en-us/services/documentdb/"
      }
    ]
  },
  {
    "name": "Microstrategy",
    "description": "software platforms for business intelligence, mobile intelligence, and network applications.",
    "abstract": "software platforms for business intelligence, mobile intelligence, and network applications",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.microstrategy.com/"
      }
    ]
  },
  {
    "name": "MLbase",
    "description": "distributed machine learning libraries for the BDAS stack",
    "abstract": "distributed machine learning libraries for the BDAS stack",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "MLbase",
        "url": "http://www.mlbase.org/"
      }
    ]
  },
  {
    "name": "MLPNeuralNet",
    "description": "Fast multilayer perceptron neural network library for iOS and Mac OS X.",
    "abstract": "Fast multilayer perceptron neural network library for iOS and Mac OS X",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/nikolaypavlov/MLPNeuralNet"
      }
    ]
  },
  {
    "name": "MonetDB",
    "description": "column store database",
    "abstract": "column store database",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.monetdb.org/"
      }
    ]
  },
  {
    "name": "MongoDB",
    "description": "Document-oriented database system. It is part of the NoSQL family of database systems. Instead of storing data in tables as is done in a \"classical\" relational database, MongoDB stores structured data as JSON-like documents",
    "abstract": "Document-oriented database system",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Mongodb site",
        "url": "http://www.mongodb.org/"
      }
    ]
  },
  {
    "name": "MPICH",
    "description": "high performance and widely portable implementation of the Message Passing Interface (MPI) standard",
    "abstract": "high performance and widely portable implementation of the Message Passing Interface (MPI) standard",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.mpich.org/"
      }
    ]
  },
  {
    "name": "Myria",
    "description": "scalable Analytics-as-a-Service platform based on relational algebra",
    "abstract": "scalable Analytics-as-a-Service platform based on relational algebra",
    "category": "Data Analysis",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://myria.cs.washington.edu/"
      }
    ]
  },
  {
    "name": "Myriad",
    "description": "a mesos framework designed for scaling YARN clusters on Mesos. Myriad can expand or shrink one or more YARN clusters in response to events as per configured rules and policies.",
    "abstract": "a mesos framework designed for scaling YARN clusters on Mesos. Myriad can expand or shrink one or more YARN clusters in response to events as per configured rules and policies.",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/mesos/myriad"
      }
    ]
  },
  {
    "name": "MySQL Cluster",
    "description": "MySQL implementation using NDB Cluster storage engine providing shared-nothing clustering and auto-sharding",
    "abstract": "MySQL implementation using NDB Cluster storage engine providing shared-nothing clustering and auto-sharding",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "MySQL Cluster",
        "url": "http://www.mysql.com/products/cluster/"
      }
    ]
  },
  {
    "name": "Neflix SimianArmy",
    "description": "a suite of tools for keeping your cloud operating in top form",
    "abstract": "a suite of tools for keeping your cloud operating in top form",
    "category": "System Deployment",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/SimianArmy"
      }
    ]
  },
  {
    "name": "Neo4j",
    "description": "An open-source graph database writting entirely in Java. It is an embedded, disk-based, fully transactional Java persistence engine that stores data structured in graphs rather than in tables.",
    "abstract": "graph database writting entirely in Java",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Neo4j site",
        "url": "http://www.neo4j.org/"
      }
    ]
  },
  {
    "name": "Netflix Aegisthus",
    "description": "Bulk Data Pipeline out of Cassandra. implements a reader for the SSTable format and provides a map/reduce program to create a compacted snapshot of the data contained in a column family",
    "abstract": "Bulk Data Pipeline out of Cassandra. implements a reader for the SSTable format and provides a map/reduce program to create a compacted snapshot of the data contained in a column family",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/aegisthus"
      }
    ]
  },
  {
    "name": "Netflix Dynomite",
    "description": "thin Dynamo-based replication for cached data",
    "abstract": "thin Dynamo-based replication for cached data",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://techblog.netflix.com/2014/03/netflixoss-season-2-episode-1.html"
      }
    ]
  },
  {
    "name": "Netflix Inviso",
    "description": "performance focused Big Data tool",
    "abstract": "performance focused Big Data tool",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://hadoopsummit.uservoice.com/forums/242807-hadoop-deployment-operations-track/suggestions/5568461-inviso-maximizing-big-data-performance-at-netflix"
      }
    ]
  },
  {
    "name": "Netflix Lipstick",
    "description": "Pig Visualization framework",
    "abstract": "Pig Visualization framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/Lipstick"
      }
    ]
  },
  {
    "name": "Netflix Mantis",
    "description": "Event Stream Processing System",
    "abstract": "Event Stream Processing System",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://qconsf.com/presentation/mantis-netflixs-event-stream-processing-system"
      }
    ]
  },
  {
    "name": "Netflix PigPen",
    "description": "PigPen is map-reduce for Clojure whiche compiles to Apache Pig. Clojure is dialect of the Lisp programming language created by Rich Hickey, so is a functional general-purpose language, and runs on the Java Virtual Machine, Common Language Runtime, and JavaScript engines. In PigPen there are no special user defined functions (UDFs). Define Clojure functions, anonymously or named, and use them like you would in any Clojure program. This tool is open sourced by Netflix, Inc. the American provider of on-demand Internet streaming media.",
    "abstract": "map-reduce for Clojure whiche compiles to Apache Pig",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "PigPen on GitHub",
        "url": "https://github.com/Netflix/PigPen"
      }
    ]
  },
  {
    "name": "Netflix Priam",
    "description": "Co-Process for backup/recovery, Token Management, and Centralized Configuration management for Cassandra",
    "abstract": "Co-Process for backup/recovery, Token Management, and Centralized Configuration management for Cassandra",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/Priam"
      }
    ]
  },
  {
    "name": "Netflix S3mper",
    "description": "library that provides an additional layer of consistency checking on top of Amazon's S3 index through use of a consistent, secondary index",
    "abstract": "library that provides an additional layer of consistency checking on top of Amazon's S3 index through use of a consistent, secondary index",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/s3mper"
      }
    ]
  },
  {
    "name": "Netflix STAASH",
    "description": "language-agnostic as well as storage-agnostic web interface for storing data into persistent storage systems",
    "abstract": "language-agnostic as well as storage-agnostic web interface for storing data into persistent storage systems",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/staash"
      }
    ]
  },
  {
    "name": "Netflix Suro",
    "description": "Suro has its roots in Apache Chukwa, which was initially adopted by Netflix. Is a log agregattor like Storm, Samza.",
    "abstract": "data pipeline service for collecting, aggregating, and dispatching large volume of application events including log data based on Chukwa",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/suro"
      }
    ]
  },
  {
    "name": "Netflix Zeno",
    "description": "Netflix's In-Memory Data Propagation Framework",
    "abstract": "Netflix's In-Memory Data Propagation Framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/zeno"
      }
    ]
  },
  {
    "name": "Nextflow",
    "description": "Dataflow oriented toolkit for parallel and distributed computational pipelines",
    "abstract": "Dataflow oriented toolkit for parallel and distributed computational pipelines",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.nextflow.io"
      }
    ]
  },
  {
    "name": "Nokia Disco",
    "description": "MapReduce framework developed by Nokia",
    "abstract": "MapReduce framework developed by Nokia",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Nokia Disco",
        "url": "http://discoproject.org/"
      }
    ]
  },
  {
    "name": "NuoDB",
    "description": "SQL/ACID compliant distributed database",
    "abstract": "SQL/ACID compliant distributed database",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "NuoDB",
        "url": "http://www.nuodb.com/"
      }
    ]
  },
  {
    "name": "nupic",
    "description": "Numenta Platform for Intelligent Computing: a brain-inspired machine intelligence platform, and biologically accurate neural network based on cortical learning algorithms.",
    "abstract": "Numenta Platform for Intelligent Computing: a brain-inspired machine intelligence platform, and biologically accurate neural network based on cortical learning algorithms",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/numenta/nupic"
      }
    ]
  },
  {
    "name": "NVD3",
    "description": "chart components for d3.js.",
    "abstract": "chart components for d3.js",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://nvd3.org/"
      }
    ]
  },
  {
    "name": "OhmData C5",
    "description": "improved version of HBase",
    "abstract": "improved version of HBase",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "OhmData website",
        "url": "http://ohmdata.com/"
      }
    ]
  },
  {
    "name": "OpenMPI",
    "description": "message passing framework",
    "abstract": "message passing framework",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "OpenMPI",
        "url": "http://www.open-mpi.org/"
      }
    ]
  },
  {
    "name": "OpenTSDB",
    "description": "OpenTSDB is a distributed, scalable Time Series Database (TSDB) written on top of HBase. OpenTSDB was written to address a common need: store, index and serve metrics collected from computer systems (network gear, operating systems, applications) at a large scale, and make this data easily accessible and graphable.",
    "abstract": "distributed time series database on top of HBase",
    "category": "Time-Series Databases",
    "tags": [
      ""
    ],
    "links": [
      {
        "text": "OpenTSDB site",
        "url": "http://opentsdb.net"
      },
      {
        "text": "Website",
        "url": "http://opentsdb.net/"
      }
    ]
  },
  {
    "name": "Oracle Database",
    "description": "object-relational database management system",
    "abstract": "object-relational database management system",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.oracle.com/us/corporate/features/database-12c/index.html"
      }
    ]
  },
  {
    "name": "Oracle NoSQL Database",
    "description": "distributed key-value database by Oracle Corporation",
    "abstract": "distributed key-value database by Oracle Corporation",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.oracle.com/technetwork/database/database-technologies/nosqldb/overview/index.html"
      }
    ]
  },
  {
    "name": "Oracle TimesTen in-Memory Database",
    "description": "in-memory, relational database management system with persistence and recoverability",
    "abstract": "in-memory, relational database management system with persistence and recoverability",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.oracle.com/technetwork/database/database-technologies/timesten/overview/index.html"
      }
    ]
  },
  {
    "name": "OrientDB",
    "description": "It is an Open Source NoSQL DBMS with the features of both Document and Graph DBMSs. Written in Java, it is incredibly fast: it can store up to 150,000 records per second on common hardware. ",
    "abstract": "document and graph database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "OrientDB site",
        "url": "http://www.orientechnologies.com/"
      }
    ]
  },
  {
    "name": "PacketPig",
    "description": "Open Source Big Data Security Analytics",
    "abstract": "Open Source Big Data Security Analytics",
    "category": "Security",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/packetloop/packetpig"
      }
    ]
  },
  {
    "name": "Parquet",
    "description": "columnar storage format for Hadoop.",
    "abstract": "columnar storage format for Hadoop",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Parquet",
        "url": "http://parquet.io/"
      }
    ]
  },
  {
    "name": "ParStream DB",
    "description": "a distributed, massively parallel processing columnar database based on a shared nothing architecture",
    "abstract": "a distributed, massively parallel processing columnar database based on a shared nothing architecture",
    "category": "https://www.parstream.com/product/parstream-db/",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "Columnar Databases"
      }
    ]
  },
  {
    "name": "Peity",
    "description": "Progressive SVG bar, line and pie charts.",
    "abstract": "Progressive SVG bar, line and pie charts",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/benpickles/peity"
      }
    ]
  },
  {
    "name": "Pentaho",
    "description": "business intelligence platform.",
    "abstract": "business intelligence platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.pentaho.com/"
      }
    ]
  },
  {
    "name": "Percona Server",
    "description": "enhanced, drop-in replacement for MySQL",
    "abstract": "enhanced, drop-in replacement for MySQL",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Percona Server",
        "url": "http://www.percona.com/software/percona-server"
      }
    ]
  },
  {
    "name": "Phoebus",
    "description": "framework for large scale graph processing",
    "abstract": "framework for large scale graph processing",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Phoebus",
        "url": "https://github.com/xslogic/phoebus"
      }
    ]
  },
  {
    "name": "PigPen",
    "description": "PigPen is map-reduce for Clojure, or distributed Clojure. It compiles to Apache Pig, but you don't need to know much about Pig to use it",
    "abstract": "PigPen is map-reduce for Clojure, or distributed Clojure. It compiles to Apache Pig, but you don't need to know much about Pig to use it",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Netflix/PigPen"
      }
    ]
  },
  {
    "name": "Pinalytics",
    "description": "Pinterestâs data analytics engine",
    "abstract": "Pinterestâs data analytics engine",
    "category": "Data Analysis",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.pinterest.com/post/104418761649/building-pinalytics-pinterests-data-analytics"
      }
    ]
  },
  {
    "name": "Pinterest Pinball",
    "description": "customizable platform for creating workflow managers",
    "abstract": "customizable platform for creating workflow managers",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.pinterest.com/post/74429563460/pinball-building-workflow-management"
      }
    ]
  },
  {
    "name": "Pinterest Pinlater",
    "description": "asynchronous job execution system",
    "abstract": "asynchronous job execution system",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://engineering.pinterest.com/post/91288882494/pinlater-an-asynchronous-job-execution-system"
      }
    ]
  },
  {
    "name": "Pivotal GemFire XD",
    "description": "Low-latency, in-memory, distributed SQL data store. Provides SQL interface to in-memory table data, persistable in HDFS.",
    "abstract": "Low-latency, in-memory, distributed SQL data store. Provides SQL interface to in-memory table data, persistable in HDFS",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://gemfirexd.docs.gopivotal.com/latest/userguide/index.html?q=about_users_guide.html/"
      }
    ]
  },
  {
    "name": "Pivotal Greenplum",
    "description": "purpose-built, dedicated analytic data warehouse",
    "abstract": "purpose-built, dedicated analytic data warehouse",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.pivotal.io/big-data/pivotal-greenplum-database"
      }
    ]
  },
  {
    "name": "Pivotal HAWQ",
    "description": "SQL-like data warehouse system for Hadoop",
    "abstract": "SQL-like data warehouse system for Hadoop",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Pivotal HAWQ",
        "url": "http://www.gopivotal.com/pivotal-products/data/pivotal-hd"
      }
    ]
  },
  {
    "name": "PivotalR",
    "description": "PivotalR is a package that enables users of R, the most popular open source statistical programming language and environment to interact with the Pivotal (Greenplum) Database as well as Pivotal HD / HAWQ and the open-source database PostgreSQL for Big Data analytics. R is a programming language and data analysis software: you do data analysis in R by writing scripts and functions in the R programming language. R is a complete, interactive,  object-oriented language: designed by statisticians, for statisticians. The language  provides objects, operators and functions that make the process of exploring, modeling, and visualizing data a natural one.",
    "abstract": "R on Pivotal HD / HAWQ and PostgreSQL",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/gopivotal/PivotalR"
      }
    ]
  },
  {
    "name": "Plot.ly",
    "description": "Easy-to-use web service that allows for rapid creation of complex charts, from heatmaps to histograms. Upload data to create and style charts with Plotly's online spreadsheet. Fork others' plots.",
    "abstract": "Easy-to-use web service that allows for rapid creation of complex charts, from heatmaps to histograms. Upload data to create and style charts with Plotly's online spreadsheet. Fork others' plots.",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://plot.ly"
      }
    ]
  },
  {
    "name": "Postgres-XL",
    "description": "Scalable Open Source PostgreSQL-based Database Cluster",
    "abstract": "Scalable Open Source PostgreSQL-based Database Cluster",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.postgres-xl.org/"
      }
    ]
  },
  {
    "name": "PredictionIO",
    "description": "machine learning server buit on Hadoop, Mahout and Cascading",
    "abstract": "machine learning server buit on Hadoop, Mahout and Cascading",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "PredictionIO",
        "url": "http://prediction.io/"
      }
    ]
  },
  {
    "name": "Pinterest Secor",
    "description": "is a service implementing Kafka log persistance",
    "abstract": "is a service implementing Kafka log persistance",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/pinterest/secor"
      }
    ]
  },
  {
    "name": "ProxySQL",
    "description": "High Performance Proxy for MySQL",
    "abstract": "High Performance Proxy for MySQL",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "ProxySQL",
        "url": "https://github.com/renecannao/proxysql"
      }
    ]
  },
  {
    "name": "Pubnub",
    "description": "Data stream network",
    "abstract": "Data stream network",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.pubnub.com/"
      }
    ]
  },
  {
    "name": "PUMA Benchmarking",
    "description": "Benchmark suite which represents a broad range of MapReduce applications exhibiting application characteristics with high/low computation and high/low shuffle volumes. There are a total of 13 benchmarks, out of which Tera-Sort, Word-Count, and Grep are from Hadoop distribution. The rest of the benchmarks were developed in-house and are currently not part of the Hadoop distribution. The three benchmarks from Hadoop distribution are also slightly modified to take number of reduce tasks as input from the user and generate final time completion statistics of jobs.",
    "abstract": "benchmark suite for MapReduce applications",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "MAPREDUCE-5116",
        "url": "https://issues.apache.org/jira/browse/MAPREDUCE-5116"
      },
      {
        "text": "Faraz Ahmad researcher",
        "url": "https://sites.google.com/site/farazahmad/"
      },
      {
        "text": "PUMA Docs",
        "url": "https://sites.google.com/site/farazahmad/pumabenchmarks"
      }
    ]
  },
  {
    "name": "Pydoop",
    "description": "Pydoop is a Python MapReduce and HDFS API for Hadoop, built upon the C++\nPipes and the C libhdfs APIs, that allows to write full-fledged  MapReduce applications with HDFS access. Pydoop has several advantages over Hadoop’s built-in solutions for Python programming, i.e., Hadoop Streaming and Jython: being a CPython package, it allows you to access all standard library and third party modules, some of which may not be available.",
    "abstract": "Python MapReduce and HDFS API for Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "SF Pydoop site",
        "url": "http://pydoop.sourceforge.net/docs/"
      },
      {
        "text": "Pydoop GitHub Project",
        "url": "https://github.com/crs4/pydoop"
      }
    ]
  },
  {
    "name": "Qlik",
    "description": "business intelligence and analytics platform.",
    "abstract": "business intelligence and analytics platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.qlik.com/"
      }
    ]
  },
  {
    "name": "Quantcast File System QFS",
    "description": " (QFS) is an open-source distributed file system software package for \nlarge-scale MapReduce or other batch-processing workloads. It was \ndesigned as an alternative to Apache Hadoop’s HDFS, intended to deliver \nbetter performance and cost-efficiency for large-scale processing clusters. \nIt is written in C++ and has fixed-footprint memory management. QFS uses \nReed-Solomon error correction as method for assuring reliable access to data. ",
    "abstract": "open-source distributed file system",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "QFS site",
        "url": "https://www.quantcast.com/engineering/qfs/"
      },
      {
        "text": "GitHub QFS",
        "url": "https://github.com/quantcast/qfs"
      },
      {
        "text": "HADOOP-8885",
        "url": "https://issues.apache.org/jira/browse/HADOOP-8885"
      }
    ]
  },
  {
    "name": "Qubole",
    "description": "auto-scaling Hadoop cluster, built-in data connectors.",
    "abstract": "auto-scaling Hadoop cluster, built-in data connectors",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.qubole.com/"
      }
    ]
  },
  {
    "name": "R-Studio",
    "description": "IDE for R.",
    "abstract": "IDE for R",
    "category": "Integrated Development Environments",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/rstudio/rstudio"
      }
    ]
  },
  {
    "name": "RabbitMQ",
    "description": "Robust messaging for applications",
    "abstract": "Robust messaging for applications",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.rabbitmq.com/"
      }
    ]
  },
  {
    "name": "RainstorDB",
    "description": "database for storing petabyte-scale volumes of structured and semi-structured data",
    "abstract": "database for storing petabyte-scale volumes of structured and semi-structured data",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://rainstor.com/products/rainstor-database/"
      }
    ]
  },
  {
    "name": "RAMCloud",
    "description": "storage system that provides large-scale low-latency storage by keeping all data in DRAM all the time and aggregating the main memories of thousands of servers",
    "abstract": "storage system that provides large-scale low-latency storage by keeping all data in DRAM all the time and aggregating the main memories of thousands of servers",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://ramcloud.atlassian.net/wiki/display/RAM/RAMCloud"
      }
    ]
  },
  {
    "name": "RavenDB",
    "description": "A transactional, open-source Document Database",
    "abstract": "A transactional, open-source Document Database",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.ravendb.net/"
      }
    ]
  },
  {
    "name": "RecDB",
    "description": "Open Source Recommendation Engine Built Entirely Inside PostgreSQL",
    "abstract": "Open Source Recommendation Engine Built Entirely Inside PostgreSQL",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www-users.cs.umn.edu/~sarwat/RecDB/"
      }
    ]
  },
  {
    "name": "Recline",
    "description": "simple but powerful library for building data applications in pure Javascript and HTML.",
    "abstract": "simple but powerful library for building data applications in pure Javascript and HTML",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/okfn/recline"
      }
    ]
  },
  {
    "name": "Record Breaker",
    "description": "Automatic structure for your text-formatted data",
    "abstract": "Automatic structure for your text-formatted data",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://cloudera.github.io/RecordBreaker/"
      }
    ]
  },
  {
    "name": "Red Hat GlusterFS",
    "description": "GlusterFS is a scale-out network-attached storage file system. GlusterFS was \ndeveloped originally by Gluster, Inc., then by Red Hat, Inc., after their \npurchase of Gluster in 2011. In June 2012, Red Hat Storage Server was \nannounced as a commercially-supported integration of GlusterFS with \nRed Hat Enterprise Linux. Gluster File System, known now as Red Hat Storage Server. ",
    "abstract": "scale-out network-attached storage file system",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "www.gluster.org",
        "url": "http://www.gluster.org/"
      },
      {
        "text": "Red Hat Hadoop Plugin",
        "url": "http://www.redhat.com/about/news/archive/2013/10/red-hat-contributes-apache-hadoop-plug-in-to-the-gluster-community"
      }
    ]
  },
  {
    "name": "Redash",
    "description": "open-source platform to query and visualize data.",
    "abstract": "open-source platform to query and visualize data",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/everythingme/redash"
      }
    ]
  },
  {
    "name": "Redis",
    "description": "Redis is an open-source, networked, in-memory, key-value data store with optional durability. It is written in ANSI C.\nIn its outer layer, the Redis data model is a dictionary which maps keys to values. One of the main differences between Redis and other structured storage systems is that Redis supports not only strings, but also abstract data types. Sponsored by Pivotal and VMWare. It’s BSD licensed.",
    "abstract": "in memory key value datastore",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Redis.io",
        "url": "http://redis.io"
      },
      {
        "text": "Website",
        "url": "http://redis.io/"
      }
    ]
  },
  {
    "name": "Redis Cluster",
    "description": "distributed implementation of Redis",
    "abstract": "distributed implementation of Redis",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://redis.io/topics/cluster-spec"
      }
    ]
  },
  {
    "name": "Redis Sentinel",
    "description": "system designed to help managing Redis instances",
    "abstract": "system designed to help managing Redis instances",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://redis.io/topics/sentinel"
      }
    ]
  },
  {
    "name": "RestMQ",
    "description": "message queue which uses HTTP as transport, JSON to format a minimalist protocol and is organized as REST resources",
    "abstract": "message queue which uses HTTP as transport, JSON to format a minimalist protocol and is organized as REST resources",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://restmq.com/"
      }
    ]
  },
  {
    "name": "RethinkDB",
    "description": "RethinkDB is built to store JSON documents, and scale to multiple machines with very little effort. It has a pleasant query language that supports really useful queries like table joins and group by, and is easy to setup and learn.",
    "abstract": "document database that supports queries like table joins and group by",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "RethinkDB site",
        "url": "http://www.rethinkdb.com/"
      }
    ]
  },
  {
    "name": "Riak",
    "description": "a decentralized datastore.",
    "abstract": "a decentralized datastore",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/basho/riak"
      }
    ]
  },
  {
    "name": "Rocket",
    "description": "an alternative to the Docker runtime, designed for server environments with the most rigorous security and production requirements",
    "abstract": "an alternative to the Docker runtime, designed for server environments with the most rigorous security and production requirements",
    "category": "Container Manager",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://coreos.com/blog/rocket/"
      }
    ]
  },
  {
    "name": "RocksDB",
    "description": "RocksDB is an embeddable persistent key-value store for fast storage. RocksDB can also be the foundation for a client-server database but our current focus is on embedded workloads.",
    "abstract": "embeddable persistent key-value store for fast storage based on LevelDB",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "RocksDB site",
        "url": "http://rocksdb.org/"
      }
    ]
  },
  {
    "name": "RQ",
    "description": "simple Python library for queueing jobs and processing them in the background with workers",
    "abstract": "simple Python library for queueing jobs and processing them in the background with workers",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://python-rq.org/"
      }
    ]
  },
  {
    "name": "SAP HANA",
    "description": "is an in-memory, column-oriented, relational database management system",
    "abstract": "is an in-memory, column-oriented, relational database management system",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.saphana.com/welcome"
      }
    ]
  },
  {
    "name": "Scalaris",
    "description": "a distributed transactional key-value store",
    "abstract": "a distributed transactional key-value store",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://code.google.com/p/scalaris/"
      }
    ]
  },
  {
    "name": "ScaleOut hServer",
    "description": "fast, scalable in-memory data grid for Hadoop",
    "abstract": "fast, scalable in-memory data grid for Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.scaleoutsoftware.com/"
      }
    ]
  },
  {
    "name": "scikit-learn",
    "description": "scikit-learn: machine learning in Python.",
    "abstract": "scikit-learn: machine learning in Python",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/scikit-learn/scikit-learn"
      }
    ]
  },
  {
    "name": "Sense",
    "description": "Cloud Platform for Data Science and Big Data Analytics",
    "abstract": "Cloud Platform for Data Science and Big Data Analytics",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://senseplatform.com/"
      }
    ]
  },
  {
    "name": "SenseiDB",
    "description": "Open-source, distributed, realtime, semi-structured database. Some Features: Full-text search, Fast realtime updates, Structured and faceted search, BQL: SQL-like query language, Fast key-value lookup, High performance under concurrent heavy update and query volumes, Hadoop integration",
    "abstract": "distributed, realtime, semi-structured database",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "SenseiDB site",
        "url": "http://senseidb.com/"
      }
    ]
  },
  {
    "name": "SeqPig",
    "description": "Simple and scalable scripting for large sequencing data set(ex: bioinfomation) in Hadoop ",
    "abstract": "Simple and scalable scripting for large sequencing data set(ex: bioinfomation) in Hadoop ",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://seqpig.sourceforge.net/"
      }
    ]
  },
  {
    "name": "Serf",
    "description": "decentralized solution for service discovery and orchestration",
    "abstract": "decentralized solution for service discovery and orchestration",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Serf",
        "url": "http://www.serfdom.io/"
      }
    ]
  },
  {
    "name": "Sidekiq",
    "description": "Simple, efficient background processing for Ruby",
    "abstract": "Simple, efficient background processing for Ruby",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://sidekiq.org/"
      }
    ]
  },
  {
    "name": "Sigma.js",
    "description": "JavaScript library dedicated to graph drawing.",
    "abstract": "JavaScript library dedicated to graph drawing",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/jacomyal/sigma.js"
      }
    ]
  },
  {
    "name": "SigmoidAnalytics Spork",
    "description": "Pig on Apache Spark",
    "abstract": "Pig on Apache Spark",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/sigmoidanalytics/spork"
      }
    ]
  },
  {
    "name": "Sky",
    "description": "Sky is an open source database used for flexible, high performance analysis of behavioral data. For certain kinds of data such as clickstream data and log data, it can be several orders of magnitude faster than traditional approaches such as SQL databases or Hadoop.",
    "abstract": "database used for flexible, high performance analysis of behavioral data",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "SkyDB site",
        "url": "http://skydb.io/"
      }
    ]
  },
  {
    "name": "Snowplow",
    "description": "enterprise-strength web and event analytics, powered by Hadoop, Kinesis, Redshift and Postgres.",
    "abstract": "enterprise-strength web and event analytics, powered by Hadoop, Kinesis, Redshift and Postgres",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/snowplow/snowplow"
      }
    ]
  },
  {
    "name": "SpagoBI",
    "description": "SpagoBI is an Open Source Business Intelligence suite, belonging to the free/open source SpagoWorld initiative, founded and supported by Engineering Group. It offers a large range of analytical functions, a highly functional semantic layer often absent in other open source platforms and projects, and a respectable set of advanced data visualization features including geospatial analytics",
    "abstract": "open source business intelligence platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.spagoworld.org/xwiki/bin/view/SpagoBI/"
      }
    ]
  },
  {
    "name": "Spark Catalyst",
    "description": "Catalyst is a Query Optimization Framework for Spark and Shark",
    "abstract": "is a Query Optimization Framework for Spark and Shark",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Github sub page",
        "url": "https://github.com/apache/spark/tree/master/sql"
      }
    ]
  },
  {
    "name": "Spark MLlib",
    "description": "a Spark implementation of some common machine learning (ML) functionality",
    "abstract": "a Spark implementation of some common machine learning (ML) functionality",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Spark Documentation",
        "url": "http://spark.apache.org/docs/0.9.0/mllib-guide.html"
      }
    ]
  },
  {
    "name": "Sparkling Water",
    "description": "combine H2OÕs Machine Learning capabilities with the power of the Spark platform",
    "abstract": "combine H2OÕs Machine Learning capabilities with the power of the Spark platform",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://databricks.com/blog/2014/06/30/sparkling-water-h20-spark.html"
      },
      {
        "text": "Website",
        "url": "http://spark-summit.org/2014/talk/sparkling-identification-of-task-skew-and-speculative-partition-of-data-for-spark-applications"
      }
    ]
  },
  {
    "name": "SparkR",
    "description": "R frontend for Spark",
    "abstract": "R frontend for Spark",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "AMPLab extras",
        "url": "http://amplab-extras.github.io/SparkR-pkg/"
      }
    ]
  },
  {
    "name": "Sparksee",
    "description": "scalable high-performance graph database",
    "abstract": "scalable high-performance graph database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.sparsity-technologies.com/"
      }
    ]
  },
  {
    "name": "SparkSQL",
    "description": "Manipulating Structured Data Using Spark",
    "abstract": "Manipulating Structured Data Using Spark",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Databricks blog post",
        "url": "http://databricks.com/blog/2014/03/26/Spark-SQL-manipulating-structured-data-using-Spark.html"
      }
    ]
  },
  {
    "name": "Sparrow",
    "description": "Sparrow is a high throughput, low latency, and fault-tolerant distributed cluster scheduler. Sparrow is designed for applications that require resource allocations frequently for very short jobs, such as analytics frameworks. Sparrow schedules from a distributed set of schedulers that maintain no shared state. Instead, to schedule a job, a scheduler obtains intantaneous load information by sending probes to a subset of worker machines. The scheduler places the job's tasks on the least loaded of the probed workers. This technique allows Sparrow to schedule in milliseconds, two orders of magnitude faster than existing approaches. Sparrow also handles failures: if a scheduler fails, a client simply directs scheduling requests to an alternate scheduler",
    "abstract": "scheduling platform",
    "category": "Scheduling",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/radlab/sparrow"
      },
      {
        "text": "Paper",
        "url": "http://dl.acm.org/citation.cfm?doid=2517349.2522716"
      }
    ]
  },
  {
    "name": "SpatialHadoop",
    "description": "SpatialHadoop is a MapReduce extension to Apache Hadoop designed specially to work with spatial data. ",
    "abstract": "SpatialHadoop is a MapReduce extension to Apache Hadoop designed specially to work with spatial data. ",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://spatialhadoop.cs.umn.edu/"
      }
    ]
  },
  {
    "name": "Sphnix Search Server",
    "description": "Sphinx lets you either batch index and search data stored in an SQL database, NoSQL storage, or just files quickly and easily — or index and search data on the fly, working with Sphinx pretty much as with a database server.",
    "abstract": "fulltext search engine",
    "category": "Search engine and framework",
    "tags": [],
    "links": [
      {
        "text": "Sphinx",
        "url": "http://sphinxsearch.com/"
      }
    ]
  },
  {
    "name": "Splice Machine",
    "description": "a full-featured SQL-on-Hadoop RDBMS with ACID transactions",
    "abstract": "a full-featured SQL-on-Hadoop RDBMS with ACID transactions",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.splicemachine.com/"
      }
    ]
  },
  {
    "name": "Splunk",
    "description": "analyzer for machine-generated date",
    "abstract": "analyzer for machine-generated date",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Splunk",
        "url": "http://www.splunk.com/"
      }
    ]
  },
  {
    "name": "Spotfire",
    "description": "business intelligence platform",
    "abstract": "business intelligence platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://spotfire.tibco.com/"
      }
    ]
  },
  {
    "name": "Spotify Luigi",
    "description": "a Python package for building complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more.",
    "abstract": "a Python package for building complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/spotify/luigi"
      }
    ]
  },
  {
    "name": "Spring for Apache Hadoop",
    "description": "unified configuration model and easy to use APIs for using HDFS, MapReduce, Pig, and Hive",
    "abstract": "unified configuration model and easy to use APIs for using HDFS, MapReduce, Pig, and Hive",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://projects.spring.io/spring-hadoop/"
      }
    ]
  },
  {
    "name": "Spring XD",
    "description": "Spring XD (Xtreme Data) is a evolution of Spring Java application development framework to help Big Data Applications by Pivotal.\nSpringSource was the company created by the founders of the Spring Framework. SpringSource was purchased by VMware where it was \nmaintained for some time as a separate division within VMware. Later VMware, and its parent company EMC Corporation, formally created \na joint venture called Pivotal. Spring XD is more than development framework library, is a distributed, and extensible system for data ingestion,\nreal time analytics, batch processing, and data export. It could be considered as alternative to Apache Flume/Sqoop/Oozie in some scenarios.\nSpring XD is part of Pivotal Spring for Apache Hadoop (SHDP). SHDP, integrated with Spring, Spring Batch and Spring Data are part of \nthe Spring IO Platform as foundational libraries. Building on top of, and extending this foundation, the Spring IO platform provides \nSpring XD as big data runtime. Spring for Apache Hadoop (SHDP) aims to help simplify the development of Hadoop based applications by \nproviding a consistent configuration and API across a wide range of Hadoop ecosystem projects such as Pig, Hive, and Cascading \nin addition to providing extensions to Spring Batch for orchestrating Hadoop based workflows.\n",
    "abstract": "distributed and extensible system for data ingestion, real time analytics, batch processing, and data export",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Spring XD on GitHub",
        "url": "https://github.com/spring-projects/spring-xd"
      }
    ]
  },
  {
    "name": "SQLStream Blaze",
    "description": "stream processing platform",
    "abstract": "stream processing platform",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.sqlstream.com/blaze/"
      }
    ]
  },
  {
    "name": "Sqrrl",
    "description": "NoSQL databases on top of Apache Accumulo",
    "abstract": "NoSQL databases on top of Apache Accumulo",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://sqrrl.com/product/sqrrl-enterprise/"
      }
    ]
  },
  {
    "name": "Square Cube",
    "description": "system for collecting timestamped events and deriving metrics",
    "abstract": "system for collecting timestamped events and deriving metrics",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://square.github.io/cube/"
      }
    ]
  },
  {
    "name": "Square Cubism.js",
    "description": "aÊD3Êplugin for visualizing time series. Use Cubism to construct better realtime dashboards, pulling data fromÊGraphite,ÊCubeÊand other sources",
    "abstract": "aÊD3Êplugin for visualizing time series. Use Cubism to construct better realtime dashboards, pulling data fromÊGraphite,ÊCubeÊand other sources",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://square.github.io/cubism/"
      }
    ]
  },
  {
    "name": "Stado",
    "description": "open source MPP database system solely targeted at data warehousing and data mart applications",
    "abstract": "open source MPP database system solely targeted at data warehousing and data mart applications",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.stormdb.com/community/stado"
      }
    ]
  },
  {
    "name": "Stardog",
    "description": "graph database: search, query, reasoning, and constraints in a lightweight, pure Java system",
    "abstract": "graph database: search, query, reasoning, and constraints in a lightweight, pure Java system",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://stardog.com/"
      }
    ]
  },
  {
    "name": "Stinger",
    "description": "interactive query for Hive",
    "abstract": "interactive query for Hive",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Stinger",
        "url": "http://hortonworks.com/labs/stinger/"
      }
    ]
  },
  {
    "name": "Storehaus",
    "description": "library to work with asynchronous key value stores, by Twitter",
    "abstract": "library to work with asynchronous key value stores, by Twitter",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Storehaus",
        "url": "https://github.com/twitter/storehaus"
      }
    ]
  },
  {
    "name": "Stratio Streaming",
    "description": "the union of a real-time messaging bus with a complex event processing engine using Spark Streaming",
    "abstract": "the union of a real-time messaging bus with a complex event processing engine using Spark Streaming",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.openstratio.org/about/stratio-streaming/"
      }
    ]
  },
  {
    "name": "Stratosphere",
    "description": "Stratosphere is a general purpose cluster computing framework. It is compatible to the Hadoop ecosystem: Stratosphere can access data stored in HDFS and runs with Hadoop's new cluster manager YARN. The common input formats of Hadoop are supported as well.\nStratosphere does not use Hadoop's MapReduce implementation: it is a completely new system that brings its own runtime. The new runtime allows to define more advanced operations that include more transformations than just map and reduce. Additionally, Stratosphere allows to express analysis jobs using advanced data flow graphs, which are able to resemble common data analysis task more naturally.",
    "abstract": "general purpose cluster computing framework",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Stratosphere site",
        "url": "http://stratosphere.eu/"
      }
    ]
  },
  {
    "name": "Streamdrill",
    "description": "usefull for counting activities of event streams over different time windows and finding the most active one",
    "abstract": "usefull for counting activities of event streams over different time windows and finding the most active one",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://streamdrill.com/"
      }
    ]
  },
  {
    "name": "Sumo Logic",
    "description": "cloud based analyzer for machine-generated data.",
    "abstract": "cloud based analyzer for machine-generated data.",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.sumologic.com/"
      }
    ]
  },
  {
    "name": "SymmetricDS",
    "description": "SymmetricDS is open source software for both file and database synchronization with support for multi-master replication, filtered synchronization, and transformation across the network in a heterogeneous environment. It supports multiple subscribers with one direction or bi-directional, asynchronous data replication. It uses web and database technologies to replicate data as a scheduled or near real-time operation. The software was designed to scale for a large number of nodes, work across low-bandwidth connections, and withstand periods of network outage. It works with most operating systems, file systems, and databases, including Oracle, MySQL, MariaDB, PostgreSQL, MS SQL Server (including Azure), IBM DB2, H2, HSQLDB, Derby, Firebird, Interbase, Informix, Greenplum, SQLite (including Android), Sybase ASE, and Sybase ASA (SQL Anywhere) databases.",
    "abstract": "open source software for both file and database synchronization",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "SymmetricDS",
        "url": "http://www.symmetricds.org/"
      }
    ]
  },
  {
    "name": "Tableau",
    "description": "business intelligence platform.",
    "abstract": "business intelligence platform",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://www.tableausoftware.com/"
      }
    ]
  },
  {
    "name": "Tachyon",
    "description": "Tachyon is an memory distributed file system. By storing the file-system contents in the main memory of all cluster nodes, the system achieves higher throughput than traditional disk-based storage systems like HDFS.",
    "abstract": "reliable file sharing at memory speed across cluster frameworks",
    "category": "Distributed Filesystem",
    "tags": [],
    "links": [
      {
        "text": "Tachyon site",
        "url": "http://tachyon-project.org/"
      }
    ]
  },
  {
    "name": "Tajo",
    "description": "Tajo is a distributed data warehouse system on Hadoop that provides low-latency and scalable ad-hoc queries and ETL on large-data sets stored on HDFS and other data sources.",
    "abstract": "distributed data warehouse system on Hadoop",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Tajo site",
        "url": "http://tajo.incubator.apache.org/"
      }
    ]
  },
  {
    "name": "Talend",
    "description": "Talend is an open source software vendor that provides data integration, data management, enterprise application integration and big data software and solutions.",
    "abstract": "unified open source environment for YARN, Hadoop, HBASE, Hive, HCatalog & Pig",
    "category": "Applications",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.talend.com/products/big-data"
      }
    ]
  },
  {
    "name": "Tarantool",
    "description": "an efficient NoSQL database and a Lua application server.",
    "abstract": "an efficient NoSQL database and a Lua application server",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/tarantool/tarantool"
      }
    ]
  },
  {
    "name": "TempoIQ",
    "description": "Cloud-based sensor analytics",
    "abstract": "Cloud-based sensor analytics",
    "category": "Time-Series Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://tempoiq.com/"
      }
    ]
  },
  {
    "name": "Tephra",
    "description": "Transactions for HBase",
    "abstract": "Transactions for HBase",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/continuuity/tephra"
      }
    ]
  },
  {
    "name": "Teradata Aster",
    "description": "Big Data Analytics",
    "abstract": "Big Data Analytics",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://it.teradata.com/Teradata-Aster-Database/"
      }
    ]
  },
  {
    "name": "Teradata Database",
    "description": "complete relational database management system",
    "abstract": "complete relational database management system",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://it.teradata.com/products-and-services/Teradata-Database/"
      }
    ]
  },
  {
    "name": "Teradata QueryGrid",
    "description": "data-access layer that can orchestrate multiple modes of analysis across multiple databases plus Hadoop",
    "abstract": "data-access layer that can orchestrate multiple modes of analysis across multiple databases plus Hadoop",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://it.teradata.com/Teradata-QueryGrid/"
      }
    ]
  },
  {
    "name": "Terrastore",
    "description": "a modern document store which provides advanced scalability and elasticity features without sacrificing consistency",
    "abstract": "a modern document store which provides advanced scalability and elasticity features without sacrificing consistency",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://code.google.com/p/terrastore/"
      }
    ]
  },
  {
    "name": "Tessera",
    "description": "Environment for Deep Analysis of Large Complex Data",
    "abstract": "Environment for Deep Analysis of Large Complex Data",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://tesseradata.org/"
      }
    ]
  },
  {
    "name": "Theano",
    "description": "Python package for deep learning that can utilize NVIDIA's CUDA toolkit to run on the GPU",
    "abstract": "Python package for deep learning that can utilize NVIDIA's CUDA toolkit to run on the GPU",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://deeplearning.net/software/theano/"
      }
    ]
  },
  {
    "name": "ThingWorx",
    "description": "Rapid development and connection of intelligent systems",
    "abstract": "Rapid development and connection of intelligent systems",
    "category": "Internet of Things",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.thingworx.com/"
      }
    ]
  },
  {
    "name": "Thunder",
    "description": "Large-scale analysis of neural data",
    "abstract": "Large-scale analysis of neural data",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://thefreemanlab.com/thunder/"
      }
    ]
  },
  {
    "name": "TIBCO ActiveSpaces",
    "description": "in-memory data grid",
    "abstract": "in-memory data grid",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.tibco.com/products/automation/in-memory-computing/in-memory-data-grid/activespaces-enterprise-edition"
      }
    ]
  },
  {
    "name": "TIBCO Enterprise Message Service",
    "description": "standards-based messaging middleware",
    "abstract": "standards-based messaging middleware",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.tibco.com/products/automation/enterprise-messaging/enterprise-message-service"
      }
    ]
  },
  {
    "name": "Tigon",
    "description": "a distributed framework built on Apache HadoopTM and Apache HBaseTM for real-time, high-throughput, low-latency data processing and analytics applications",
    "abstract": "a distributed framework built on Apache HadoopTM and Apache HBaseTM for real-time, high-throughput, low-latency data processing and analytics applications",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://cask.co/products/tigon/"
      }
    ]
  },
  {
    "name": "Titan",
    "description": "distributed graph database, built over Cassandra",
    "abstract": "distributed graph database, built over Cassandra",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Titan",
        "url": "http://thinkaurelius.github.io/titan/"
      }
    ]
  },
  {
    "name": "TokioCabinet",
    "description": "a library of routines for managing a database",
    "abstract": "a library of routines for managing a database",
    "category": "Embedded Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://fallabs.com/tokyocabinet/"
      }
    ]
  },
  {
    "name": "TokuDB",
    "description": "TokuDB is a storage engine for MySQL and MariaDB that is specifically designed for high performance on write-intensive workloads. It achieves this via Fractal Tree indexing. TokuDB is a scalable, ACID and MVCC compliant storage engine. TokuDB is one of the technologies that enable Big Data in MySQL.",
    "abstract": "TokuDB is a storage engine for MySQL and MariaDB",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.tokutek.com/products/tokudb-for-mysql/"
      }
    ]
  },
  {
    "name": "TokuMX",
    "description": "High-Performance MongoDB Distribution",
    "abstract": "High-Performance MongoDB Distribution",
    "category": "Document Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.tokutek.com/products/tokumx-for-mongodb/"
      }
    ]
  },
  {
    "name": "Torch",
    "description": "Scientific computing for LuaJIT",
    "abstract": "Scientific computing for LuaJIT",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://torch.ch/"
      }
    ]
  },
  {
    "name": "Trafodion",
    "description": "enterprise-class SQL-on-HBase solution targeting big data transactional or operational workloads",
    "abstract": "enterprise-class SQL-on-HBase solution targeting big data transactional or operational workloads",
    "category": "SQL-like processing",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://wiki.trafodion.org/wiki/index.php/Main_Page"
      }
    ]
  },
  {
    "name": "TreodeDB",
    "description": "key-value store that's replicated and sharded and provides atomic multirow writes",
    "abstract": "key-value store that's replicated and sharded and provides atomic multirow writes",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Treode/store"
      }
    ]
  },
  {
    "name": "Twemproxy",
    "description": "A fast, light-weight proxy for memcached and redis",
    "abstract": "A fast, light-weight proxy for memcached and redis",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Github",
        "url": "https://github.com/twitter/twemproxy"
      }
    ]
  },
  {
    "name": "Twitter Elephant Bird",
    "description": "Elephant Bird is a project that provides utilities (libraries) for working with LZOP-compressed data. It also provides a container format that supports working with Protocol Buffers, Thrift in MapReduce, Writables, Pig LoadFuncs, Hive SerDe, HBase miscellanea. This open source library is massively used in Twitter.",
    "abstract": "libraries for working with LZOP-compressed data",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Elephant Bird GitHub",
        "url": "https://github.com/kevinweil/elephant-bird"
      }
    ]
  },
  {
    "name": "Twitter Fatcache",
    "description": "key/value cache for flash storage",
    "abstract": "key/value cache for flash storage",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Twitter Fatcache",
        "url": "https://github.com/twitter/fatcache"
      }
    ]
  },
  {
    "name": "Twitter Finagle",
    "description": "Finagle is an asynchronous network stack for the JVM that you can use to build asynchronous Remote Procedure Call (RPC) clients and servers in Java, Scala, or any JVM-hosted language.",
    "abstract": "asynchronous network stack for the JVM",
    "category": "Service Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://twitter.github.io/finagle/"
      }
    ]
  },
  {
    "name": "Twitter FlockDB",
    "description": "distribuited graph database",
    "abstract": "distribuited graph database",
    "category": "Graph Data Model",
    "tags": [],
    "links": [
      {
        "text": "Twitter FlockDB",
        "url": "https://github.com/twitter/flockdb"
      }
    ]
  },
  {
    "name": "Twitter Manhattan",
    "description": "real-time, multi-tenant distributed database for Twitter scale",
    "abstract": "real-time, multi-tenant distributed database for Twitter scale",
    "category": "Key-Map Data Model",
    "tags": [],
    "links": [
      {
        "text": "Blog post on Twitter Engineering blog",
        "url": "https://blog.twitter.com/2014/manhattan-our-real-time-multi-tenant-distributed-database-for-twitter-scale"
      }
    ]
  },
  {
    "name": "Twitter Scalding",
    "description": "Scala library for Map Reduce jobs, built on Cascading",
    "abstract": "Scala library for Map Reduce jobs, built on Cascading",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Twitter Scalding",
        "url": "https://github.com/twitter/scalding"
      }
    ]
  },
  {
    "name": "Twitter Summingbird",
    "description": "a system that aims to mitigate the tradeoffs between batch processing and stream processing by combining them into a hybrid system. In the case of Twitter, Hadoop handles batch processing, Storm handles stream processing, and the hybrid system is called Summingbird.",
    "abstract": "Streaming MapReduce with Scalding and Storm, by Twitter",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Summingbird",
        "url": "https://github.com/twitter/summingbird"
      }
    ]
  },
  {
    "name": "Twitter TSAR",
    "description": "TimeSeries AggregatoR by Twitter",
    "abstract": "TimeSeries AggregatoR by Twitter",
    "category": "Distributed Programming",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://blog.twitter.com/2014/tsar-a-timeseries-aggregator"
      },
      {
        "text": "Website",
        "url": "http://gigaom.com/2014/06/27/twitter-details-how-new-home-grown-system-coordinates-data-analytics/"
      }
    ]
  },
  {
    "name": "Twitter Twemcache",
    "description": "fork of Memcache",
    "abstract": "fork of Memcache",
    "category": "Memcached forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Twitter Twemcache",
        "url": "https://github.com/twitter/twemcache"
      }
    ]
  },
  {
    "name": "Twitter Zipkin",
    "description": "distributed tracing system that helps us gather timing data for all the disparate services at Twitter",
    "abstract": "distributed tracing system that helps us gather timing data for all the disparate services at Twitter",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/twitter/zipkin"
      }
    ]
  },
  {
    "name": "Vahara",
    "description": "Machine learning and natural language processing with Apache Pig",
    "abstract": "Machine learning and natural language processing with Apache Pig",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/Ganglion/varaha"
      }
    ]
  },
  {
    "name": "Vega",
    "description": "a visualization grammar.",
    "abstract": "a visualization grammar",
    "category": "Data Visualization",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/trifacta/vega"
      }
    ]
  },
  {
    "name": "Vertica",
    "description": "The grid-based, column-oriented, Vertica Analytics Platform is designed to manage large, fast-growing volumes of data and provide very fast query performance when used for data warehouses and other query-intensive applications. The product claims to drastically improve query performance over traditional relational database systems, provide high-availability, and petabyte scalability on commodity enterprise servers.",
    "abstract": "is designed to manage large, fast-growing volumes of data and provide very fast query performance when used for data warehouses",
    "category": "Columnar Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.vertica.com/"
      }
    ]
  },
  {
    "name": "Vibe Data Stream",
    "description": "streaming data collection for real-time Big Data analytics",
    "abstract": "streaming data collection for real-time Big Data analytics",
    "category": "Data Ingestion",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.informatica.com/us/products/big-data/vibe-data-stream/"
      }
    ]
  },
  {
    "name": "Virtuoso",
    "description": "a scalable cross-platform server that combines Relational, Graph, and Document Data Management with Web Application Server and Web Services Platform functionality",
    "abstract": "a scalable cross-platform server that combines Relational, Graph, and Document Data Management with Web Application Server and Web Services Platform functionality",
    "category": "http://virtuoso.openlinksw.com/",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "NewSQL Databases"
      }
    ]
  },
  {
    "name": "Viv",
    "description": "global platform that enables developers to plug into and create an intelligent, conversational interface to anything",
    "abstract": "global platform that enables developers to plug into and create an intelligent, conversational interface to anything",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://viv.ai/"
      }
    ]
  },
  {
    "name": "Voltage SecureData",
    "description": "data protection framework",
    "abstract": "data protection framework",
    "category": "Security",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.voltage.com/products/securedata-enterprise/"
      }
    ]
  },
  {
    "name": "VoltDB",
    "description": "in-memory NewSQL database",
    "abstract": "in-memory NewSQL database",
    "category": "NewSQL Databases",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://voltdb.com/"
      }
    ]
  },
  {
    "name": "Vowpal Wabbit",
    "description": "learning system sponsored by Microsoft and Yahoo!",
    "abstract": "learning system sponsored by Microsoft and Yahoo!",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Vowpal Wabbit",
        "url": "https://github.com/JohnLangford/vowpal_wabbit/wiki"
      }
    ]
  },
  {
    "name": "WebScaleSQL",
    "description": "is a collaboration among engineers from several companies that face similar challenges in running MySQL at scale, and seek greater performance from a database technology tailored for their needs.",
    "abstract": "is a collaboration among engineers from several companies that face similar challenges in running MySQL at scale",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://webscalesql.org/"
      }
    ]
  },
  {
    "name": "WEKA",
    "description": "Weka (Waikato Environment for Knowledge Analysis) is a popular suite of machine learning software written in Java, developed at the University of Waikato, New Zealand. Weka is free software available under the GNU General Public License.",
    "abstract": "suite of machine learning software",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.cs.waikato.ac.nz/ml/weka/"
      }
    ]
  },
  {
    "name": "Wit",
    "description": "Natural Language for the Internet of Things",
    "abstract": "Natural Language for the Internet of Things",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://wit.ai/"
      }
    ]
  },
  {
    "name": "Wolfram Alpha",
    "description": "computational knowledge engine",
    "abstract": "computational knowledge engine",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.wolframalpha.com/"
      }
    ]
  },
  {
    "name": "Yahoo Everest",
    "description": "multi-peta-byte database / MPP derived by PostgreSQL",
    "abstract": "multi-peta-byte database / MPP derived by PostgreSQL",
    "category": "PostgreSQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.scribd.com/doc/3159239/70-Everest-PGCon-RT"
      }
    ]
  },
  {
    "name": "Yahoo Gridmix3",
    "description": "Hadoop cluster benchmarking from Yahoo engineer team.",
    "abstract": "Hadoop cluster benchmarking from Yahoo engineer team",
    "category": "Benchmarking",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://developer.yahoo.com/blogs/hadoop/gridmix3-emulating-production-workload-apache-hadoop-450.html"
      }
    ]
  },
  {
    "name": "Yahoo Sherpa",
    "description": "hosted, distributed and geographically replicated key-valueÊcloud storage platform",
    "abstract": "hosted, distributed and geographically replicated key-valueÊcloud storage platform",
    "category": "Key-value Data Model",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://en.wikipedia.org/wiki/Yahoo_Sherpa"
      }
    ]
  },
  {
    "name": "YHat ScienceOps",
    "description": "platform for deploying, managing, and scaling predictive models in production applications",
    "abstract": "platform for deploying, managing, and scaling predictive models in production applications",
    "category": "Machine Learning",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://yhathq.com/products/scienceops"
      }
    ]
  },
  {
    "name": "Youtube Vitess",
    "description": "provides servers and tools which facilitate scaling of MySQL databases for large scale web services",
    "abstract": "provides servers and tools which facilitate scaling of MySQL databases for large scale web services",
    "category": "MySQL forks and evolutions",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "https://github.com/youtube/vitess"
      }
    ]
  },
  {
    "name": "Zeppelin",
    "description": "open source data analysis environment on top of Hadoop.",
    "abstract": "open source data analysis environment on top of Hadoop.",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://zeppelin-project.org/"
      }
    ]
  },
  {
    "name": "ZeroMQ",
    "description": "The Intelligent Transport Layer",
    "abstract": "The Intelligent Transport Layer",
    "category": "Message-oriented middleware",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.zeromq.org/"
      }
    ]
  },
  {
    "name": "Zillabyte",
    "description": "an API for distributed data computation. Scale with your data.",
    "abstract": "an API for distributed data computation. Scale with your data.",
    "category": "Data Analysis",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://zillabyte.com/"
      }
    ]
  },
  {
    "name": "Zoomdata",
    "description": "Big Data Analytics",
    "abstract": "Big Data Analytics",
    "category": "Business Intelligence",
    "tags": [],
    "links": [
      {
        "text": "Website",
        "url": "http://www.zoomdata.com/"
      }
    ]
  }
]